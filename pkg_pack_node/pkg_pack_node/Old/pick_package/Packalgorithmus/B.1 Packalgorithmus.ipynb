{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Packalgorithmus\n",
    "Autor: Dominik Lipfert, <br />\n",
    "Matrikelnummer: 67323, <br />\n",
    "Studiengang:Wirtschaftsingenierwesen Master <br />\n",
    "<br />\n",
    "basierend auf dem Packalgorithmus von Reiplinger (2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gliederung\n",
    "0. Klassen des Packalgorithmus\n",
    " - Class: Article\n",
    " - Class: Container\n",
    " - Class: Solution (=Individuum)\n",
    " - Class: Genetic Algorithm\n",
    " - Class: Packing Algorithm\n",
    " - Class: Grid Search\n",
    "1. Datenvorverarbeitung \n",
    "2. Restriktionen in Cython\n",
    " - Platzierungsbedingungen\n",
    " - Bedingung für Traglast einzelner Packstücke\n",
    "3. Anwendung & Ergebnisausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_28812\\1020292281.py:4: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_28812\\1020292281.py:17: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from IPython.core.display import display, HTML\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "%load_ext Cython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Klassen des Packalgorithmus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    def __init__(self, width, height, length, x, y, z, is_stack, package_ID, package_sequence_nr, package_weight):\n",
    "        self.width = width # Packstückbreite\n",
    "        self.height = height # Packstückhöhe\n",
    "        self.length = length # Packstücklänge\n",
    "        self.x = x # Breitenkoordinate\n",
    "        self.y = y # Höhenkoordinate\n",
    "        self.z = z # Längenkoordinate\n",
    "        self.is_stack = is_stack # 0 wenn sich keine Packstücke auf dem Packstück befinden, sonst 1\n",
    "        self.package_ID = package_ID # eindeuitge ID des Packstücks\n",
    "        self.package_sequence_nr = package_sequence_nr # Entspritcht Reihenfolge, nachdem Packstücke in Container gepackt werden\n",
    "        self.package_weight = package_weight # Gewicht des Packstücks\n",
    "        self.supported_articles = [(0,0)] # Tupel mit (Packstück-ID, anteiliges Gewicht) von Packstücken, umittelbar auf diese Packstück-Instanz\n",
    "\n",
    "    def set_is_stack_to_true(self):\n",
    "        self.is_stack = True\n",
    "\n",
    "    # Überprüfe beim beladen des Packstücks mit einer zusätzliche Last, ob die maximale Traglast des Packstücks durch diese überschritten wird\n",
    "    def check_if_article_has_overload(self, weight_of_article_to_stack):\n",
    "        \n",
    "        # Definiere den Faktor, der vorgierbt das Wievielfache seines Eigengewicht ein Packstück tragen darf\n",
    "        overload_factor = 1.0\n",
    "\n",
    "        # Initialisiere die Variable, die bestimmt ob das Packstück überladen ist\n",
    "        article_has_overload = False\n",
    "\n",
    "        supported_weights = [supported_article[1] for supported_article in self.supported_articles] # Erzeuge eine Liste, welche die Last jedes einzelnen Packstücks enthät, das das Packstück bereits trägt\n",
    "        supported_weight_sum = reduce(add, supported_weights) # Berechne die gesamte Last, die das Packstück bereits trägt\n",
    "\n",
    "        if ((supported_weight_sum + weight_of_article_to_stack) > (self.package_weight * overload_factor)): # Prüfe ob die gesamte Last die das Pakcstück bereits trägt + die zusätzliche Last durch das neue Packstück die maximale Traglast übersteigt\n",
    "            article_has_overload = True # Setzte die Variable, die bestimmt ob das Packstück überladen ist auf True\n",
    "        \n",
    "        return article_has_overload # Liefere die Information, ob das Packstück durch die zusätzliche Last überladen wird zurück\n",
    "\n",
    "    # Fügt Packstück ID und die damit verbundene Last der Liste alle Packstücke, die durch diese Packstück getragen werden hinzu\n",
    "    def add_supported_article(self, supported_article_ID, supported_article_weight):\n",
    "        self.supported_articles.append((supported_article_ID, supported_article_weight))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "box = collections.namedtuple('box', 'width height length')\n",
    "\n",
    "class Container:\n",
    "    \n",
    "    def __init__(self, container_width, container_height, container_length, container_costs, max_weight, rest_packages):\n",
    "        self.container = box(container_width, container_height, container_length) # Container Dimensionen\n",
    "        self.costs = container_costs # Containerkosten\n",
    "        self.max_weight = max_weight # Maximaltraglast des Containers\n",
    "        self.carried_weight = 0 # Initialisiere Variable für das gepackte Gewicht des Containers\n",
    "        self.article_locations = [] # Initialisiere Liste, in welche alle Packstücke gespeichert werden, die der Container enthält\n",
    "        self.volume_used = 0 # Initialisiere Variable für das genutzte Volumen des Containers\n",
    "        self.volume_usage_rate = 0 # Initialisiere Variable für das Containerauslastung in Prozent\n",
    "\n",
    "        '''Variablen die der SKA für die Containerbefüllung benötigt'''\n",
    "        self.rest_packages = rest_packages # Initialisiere Liste mit allen noch nicht gepackten Packstücken\n",
    "        self.packages_packed = [] # Speichere platzierte Packstücke separat ab. Hierüber werden später die platzierten Packstücke aus den modifizierten Bestelldaten entfernt.\n",
    "        self.package_sequence_nr = 1 # Initialisierung der Variable für die Packreihenfolge, mit der nachvollzogen werden kann, in welcher Reihenfolge die Packstücke in den Container gepackt werden\n",
    "        self.call_from_stack_building = False # Initialisiere Variable um zu definieren, ob das die Add_One_Raw Funktion durch eine Stack Building Funktion aufgerufen wird\n",
    "\n",
    "        self.factor_overfilling = 1.05 # Parameter, welcher die maximale Überschreitung von der Reihenlänge vorgibt. 1,05 entspricht einer Überschreitung von 5 % der Reihenlänge.\n",
    "\n",
    "        self.articles_from_width_extension = [] # Initialisiere Liste, welche durch die width_extension mit Tupeln befüllt wird, im Falle von call_from_stack_building = False bleibt diese Liste leer\n",
    "        self.articles_from_length_extension = [] # Initialisiere Liste, welche durch die length_extension mit Tupeln befüllt wird, im Falle von call_from_stack_building = False bleibt diese Liste leer\n",
    "\n",
    "        # Initialisiere Startkoordinaten für die Platzierung von Packstücken in dem Container\n",
    "        self.main_box_width = 0 \n",
    "        self.main_box_height = 0\n",
    "        self.main_box_length = 0\n",
    "\n",
    "        # Initialisiere verfügbare Länge auf dem Boden des Containers (genannt Schichtlänge)\n",
    "        # Die Schichtlänge wird nach dem Platzieren einer Hauptreihe um die Länge der Hauptreihe reduziert\n",
    "        # Sie gibt damit die initiale Leerraumlänge vor dem Platzieren eine Hauptreihe vor\n",
    "        self.main_layer_length = container_length # Initialisierung mit gesamter Containerlänge des Containertyps\n",
    "\n",
    "        # Für das Wall-Buikding:\n",
    "        # Anfangs steht der gesamte Container zur Bildung einer Reihe zur Verfügung\n",
    "        self.main_raw_width = container_width # Breite des Leerraums\n",
    "        self.main_raw_length = container_length # Länge des Leerraums\n",
    "\n",
    "        # Für das Raw & Layer Building:\n",
    "        self.articles_in_raw = [] # Liste in welche alle Artikel einer Raw/Layer gespeichert werden\n",
    "\n",
    "        \n",
    "        '''Ende Variablen die der SKA für die Containerbefüllung benötigt'''\n",
    "\n",
    "    def add_article(self, width, height, length, x, y, z, is_stack, package_ID, package_sequence_nr, package_weight):\n",
    "        self.article_locations.append(Article(width, height, length, x, y, z, is_stack, package_ID, package_sequence_nr, package_weight)) # Füge Packstück hinzu\n",
    "        self.volume_used += (width * height * length)/1000000 # Erhöhe das genutze Volumen des Containers um das Volumen des hinzugefügten Packstücks\n",
    "        self.carried_weight += package_weight # Erhöhe das Containergewicht um das Gewicht des hinzugefügten Packstücks\n",
    "        \n",
    "\n",
    "    def remove_article(self, article):\n",
    "        self.article_locations.remove(article)\n",
    "        self.volume_used -= (article.width * article.height * article.length)/1000000 # Verringere das genutze Volumen des Containers um das Volumen des entfernten Artikels\n",
    "        self.carried_weight -= article.package_weight # Verringere das Containergewicht um das Gewicht des entfernten Packstücks\n",
    "    \n",
    "    def set_volume_usage(self, container_volume_usage):\n",
    "        self.volume_used = container_volume_usage\n",
    "\n",
    "    # Berechne Containerauslastung in Prozent\n",
    "    def set_volume_usage_rate(self):\n",
    "        self.volume_usage_rate = (self.volume_used/((self.container.width*self.container.height*self.container.length)/1000000))*100 \n",
    "\n",
    "    def Check_Overload_Of_Artcicles (self, selected_orientation):\n",
    "    \n",
    "        # Initialisiere Variable, die bestimmt, ob die Platzierung des übergebenen Packstücks zulässig ist\n",
    "        placement_allowed = True\n",
    "\n",
    "        # Erzeuge eine Listen mit den Informationen welche Packstücke der Stapelgrundfläche mit welcher Fläche das zu stapelnde Packstück tragen. In Form von Tupeln: (Packstück ID, tragende Fläche)\n",
    "        # 1. Funktionsaufruf; Übergebe: zu packendes Packstück; Packstück welches die Basis der Stapelfläche bildet + alle Packstücke durch die die Stapelgrundfläche der Breite nach erweitert wurde\n",
    "        # 2. Funktionsaufruf; Übergebe: zu packendes Packstück; alle Packstücke durch die die Stapelgrundfläche der Länge nach erweitert wurde\n",
    "        list_with_covered_areas = Calculate_Overlapping_Areas(selected_orientation, self.articles_from_width_extension) + Calculate_Overlapping_Areas(selected_orientation, self.articles_from_length_extension)\n",
    "        \n",
    "        # Initialisiere die Packstück ID des zu packenden Packstücks\n",
    "        package_ID_article_to_stack = selected_orientation[7]\n",
    "        # Initialisiere das Gewicht des zu packenden Packstücks\n",
    "        weight_article_to_stack = selected_orientation[8]\n",
    "        \n",
    "        # Initialisiere eine Variable, welche die gesamte Fläche auf der das zu packende Packstück aufliegt speichert\n",
    "        area_used_of_base = 0\n",
    "        # Berechne die gesamte Fläche auf der das zu packende Packstück aufliegt\n",
    "        for article_base in list_with_covered_areas:\n",
    "            area_used_of_base += article_base[1]\n",
    "\n",
    "        # Weise das Gewicht des zu stapelnden Packstücks anteilig auf die Packstücke der Stapelgrundfläche zu, auf denen es aufliegt & überprüfe ob dadurch eine Überladung zustande kommt\n",
    "        for article_base in list_with_covered_areas:\n",
    "            area_article_base = article_base[1] # Initialisiere die Größe der tragenden Fläche des Packstücks, welches beladen wird\n",
    "            package_ID_article_base = article_base[0] # Initialisiere die Packstück ID des Packstücks, welches beladen wird\n",
    "            covered_weight = 0 # Initialisiere das Gewicht, welches das Packstück, welches beladen wird, zu tragen hat\n",
    "                    \n",
    "            if(len(list_with_covered_areas) == 1): # Überprüfe, ob ein Packstück der Grundfläche das gesamte zu stapelnde Packstück trägt\n",
    "                covered_weight = weight_article_to_stack # Weise das Gemsatgewicht des zu stapelnden Packstücks dem einen Packstück zu\n",
    "            \n",
    "            else: # Mehrere Packstücke targen das zu packende Packstück\n",
    "                covered_weight = area_article_base/area_used_of_base * weight_article_to_stack # Weise das Gewicht des zu stapelnden Packstücks dem Packstück anteilig zu (tragende Fläche des Packstücks / Gesamte tragende Fläche * Gewicht)\n",
    "            \n",
    "            # Überprüfe für das zu beladende Packstück, ob es überladen ist, falls das zu stapelnde Packstück (anteilig) darauf gestapelt wird\n",
    "            for article in self.article_locations:\n",
    "                if (article.package_ID == package_ID_article_base and article.check_if_article_has_overload(covered_weight)):\n",
    "                    placement_allowed = False # Falls es überladen ist, erlaube die Platzierung des zu stapelnden Packstücks nicht\n",
    "\n",
    "        # Überprüfe abschließend, ob das zu stapelnde Packstück platziert werden darf & füge das (anteilig) getragene Gewicht des zu stapelnden Packstücks allen als Stapelfläche dienene tragenden Packstücken hinzu    \n",
    "        if (placement_allowed == True):\n",
    "            for article_base in list_with_covered_areas:\n",
    "                package_ID_article_base = article_base[0] # Initialisiere die Packstück ID des Packstücks, welches beladen wird\n",
    "                for article in self.article_locations:\n",
    "                    if (article.package_ID == package_ID_article_base):\n",
    "                        article.add_supported_article(package_ID_article_to_stack, covered_weight) # Füge das getragene Gewicht der Liste aller getragenene Gewichte des Packstücks hinzu      \n",
    "        \n",
    "        return placement_allowed\n",
    "\n",
    "    '''Funktionen des Single Knapsack Algortihmus'''\n",
    "    # Heuristik zur Befüllung eines Containers\n",
    "    def pack_container (self):\n",
    "    \n",
    "        # Führe Wallbuilding durch\n",
    "        raw_length_list = self.run_Wall_Building()\n",
    "        \n",
    "        # Führe Postoptmierung durch \n",
    "        self.run_Post_Optimization(raw_length_list)\n",
    "    \n",
    "        return self.packages_packed\n",
    "\n",
    "    def run_Wall_Building (self):\n",
    "\n",
    "        # Solange Restartikel bzw. Restpackstücke übrig sind, bilde Reihen\n",
    "        while len(self.rest_packages) > 0:\n",
    "            rest_packages_old = len(self.rest_packages) # Variable, welche der Anzahl an verbleibenden Packstücke entspricht. Diese wird als Abbruchkriterium verwendet.\n",
    "            \n",
    "            self.factor_overfilling = 1.05  # Parameter, welcher die maximale Überschreitung von der Reihenlänge vorgibt. 1,05 entspricht einer Überschreitung von 5 % der Reihenlänge.\n",
    "            \n",
    "            self.call_from_stack_building = False # Setzte Variable auf False, die bestimmt ob die Add_One_Raw Funktion durch eine Stack Building Funktion aufgerufen wird\n",
    "\n",
    "            # Rufe Methode zur Bildung einer Reihe auf\n",
    "            # Erhalte: Liste mit Packstücklängen\n",
    "            raw_length_list = self.Add_One_Raw (self.main_raw_width, self.main_raw_length, self.main_box_width, self.main_box_length, self.main_box_height)\n",
    "            \n",
    "            # Terminiere Wall-Building, sofern keine weiteren Packstücke und damit keine weitere Wall erzeugt werden konnte\n",
    "            # In diesem Falle müssen genauso viele Restpackstücke existieren wie vor dem Raw-Building\n",
    "            if len(self.rest_packages) == rest_packages_old: \n",
    "                break\n",
    "            \n",
    "            # Rufe Methode zur Bildung eines Stapels auf\n",
    "            # Durchlaufe die bereits platzierten Packstücke. Jedes platzierte Packstück wird als Stapel angesehen.\n",
    "            for article_packed in self.article_locations:\n",
    "                self.Stack_Building (article_packed)\n",
    "            # Nun ist eine Wall komplettiert\n",
    "\n",
    "            # Setze Koordinate für neue Haptreihe\n",
    "            self.main_box_length = self.main_box_length + max(raw_length_list) # Neue Längenposition entspricht alter Längenposition zuzüglich der maximalen Länge der platzierten Reihe\n",
    "            self.main_box_width = 0 # Breitenposition wird zurückgesetzt\n",
    "            self.main_box_height = 0 # Höhenposition wird zurückgesetzt\n",
    "            \n",
    "            # Errechne den neuen Leerraum für die nächste Hauptreihe auf dem Containerboden\n",
    "            self.main_raw_length = self.main_layer_length - max(raw_length_list) # Verbleibender Leerraum entspricht der Schichtlänge abzüglich der maximalen Länge der platzierten Reihe\n",
    "            self.main_raw_width = self.container.width # Verfügbare Reihenbreite wird auf Containebreite zurückgesetzt\n",
    "\n",
    "\n",
    "        return raw_length_list\n",
    "\n",
    "\n",
    "    def run_Post_Optimization(self, raw_length_list):\n",
    "        \n",
    "        # Bestimme minimale Packstückdimension\n",
    "        # Die minimale Dimension eines Leerraums muss größer oder gleich der minimalen Packstückdimension sein --> Einsparung Rechenzeit\n",
    "        min_dimension = 1000\n",
    "        for package in self.rest_packages:\n",
    "            dimensions = [package[0][2],package[0][3], package[0][4]]\n",
    "            if min(dimensions) < min_dimension:\n",
    "                min_dimension = min(dimensions)\n",
    "                \n",
    "        # Erzeuge Empty Spaces\n",
    "        empty_spaces = self.Create_Empty_Spaces(min_dimension)\n",
    "\n",
    "        # Befülle die einzelnen Leerräume\n",
    "        for empty_space in empty_spaces:\n",
    "            \n",
    "            # Erzeuge den betrachteten Leerraum\n",
    "            empty_space_width = empty_space[0]\n",
    "            empty_space_length = empty_space[1]\n",
    "            empty_space_height = empty_space[2]\n",
    "            # Setze Leerraumkoordinaten\n",
    "            empty_space_x = empty_space[3]\n",
    "            empty_space_z = empty_space[5]\n",
    "            empty_space_y = empty_space[4]\n",
    "            \n",
    "            # Eine Überschreitung der Reihenlänge ist nun nicht mehr erlaubt\n",
    "            self.factor_overfilling = 1.0 \n",
    "            \n",
    "            # Speichere die Packstücke aus der Schicht in einer Liste ab\n",
    "            articles_in_raw = []\n",
    "            \n",
    "            # Erzeuge eine Schicht auf dem Boden des Containers\n",
    "            raw_length_list = self.Add_Single_Layer (raw_length_list, empty_space_width, empty_space_length, empty_space_x, empty_space_y, empty_space_z)\n",
    "            \n",
    "            # Entferne Packstücke aus der einzelnen Schicht von den verbleibenden Packstücken\n",
    "            # Im Gegensatz zu den Modulen Stack-Building und Add_One_Raw, entfernt Add_Single_Layer die platzierten Packstücke nicht selbstständig          \n",
    "            self.remove_packed_articles_from_rest_packages()  \n",
    "            \n",
    "            # Wiederhole Stapelvorgang\n",
    "            for article_packed in self.article_locations:\n",
    "                self.Stack_Building (article_packed)\n",
    "                \n",
    "        # Führe finale Stapelung mit zugelassenen Überhängen durch\n",
    "        for article_packed in self.article_locations:\n",
    "\n",
    "            self.Modified_Stack_Building (article_packed)\n",
    "\n",
    "\n",
    "    def remove_packed_articles_from_rest_packages(self):\n",
    "        # Entferne die platzierten Packstücke aus den verbleibenden Packstücken\n",
    "        for package_to_remove in self.articles_in_raw:\n",
    "            self.rest_packages.remove(package_to_remove)\n",
    "\n",
    "\n",
    "\n",
    "    def Add_One_Raw (self, main_raw_width, main_raw_length, main_box_width, main_box_length, main_box_height):\n",
    "    \n",
    "        # Initialisiere Liste für Packstücke in der Hauptreihe\n",
    "        self.articles_in_raw = []\n",
    "        \n",
    "        # Speichere die Längen-Dimensionen der Packstücke einer Reihe in einer Liste ab. \n",
    "        # Das Packstück mit der größten Länge gibt die Verschiebung der Längen-Koordinate (box_length) nach Erzeugung der Reihe vor.\n",
    "        raw_length_list = []\n",
    "        \n",
    "        # Beginne mit der Reihenbildung\n",
    "        for article in self.rest_packages: # Durchlaufe alle Packstücke\n",
    "                    \n",
    "            selected_orientation = () # Initialisiere ein Tupel, in welches die Orientierung des potenziell zu platzierenden Packstücks gespeichert wird\n",
    "\n",
    "            for orientation in article: # Durchlaufe die möglichen Orientierungen eines Packstücks (sortiert nach größtmöglicher Grundfläche)\n",
    "                                    \n",
    "                # Überprüfe ob das betrachtete Packstück in der betrachteten Orientierung platziert werden kann\n",
    "                if (Check_Placement(article, self.articles_in_raw, self.container, self.max_weight, self.carried_weight, orientation, main_raw_width, main_raw_length, main_box_length, main_box_height, self.factor_overfilling) == True):\n",
    "                    \n",
    "                    # Speichere die Daten über die Orientierung zwischen, welche potenziell platziert werden kann\n",
    "                    possible_orientation = (orientation[2], orientation[4], orientation[3], main_box_width, main_box_height, main_box_length, False, orientation[1], orientation[5])\n",
    "                    # Prüfe ob das Raw Building im Rahmen einer Stapelung durchgeführt wird\n",
    "                    if (self.call_from_stack_building == True):\n",
    "\n",
    "                        # Rufe Methode zur Prüfung der Überschreitung der maximalen Traglast auf\n",
    "                        # Übergebe: Orientierung, Packstücke der Stapelgrundfläche aus width_extension, Packstücke der Stapelgrundfläche aus length_extension, welche Gewichtzuweisung aller gepackten Packstücke enthält\n",
    "                        # Erhalte: Information, ob Platzierung zulässig\n",
    "                        placement_allowed = self.Check_Overload_Of_Artcicles(possible_orientation)\n",
    "                        \n",
    "                        if (placement_allowed == True): # Prüfe ob die Orientierung platziert werden darf\n",
    "                            selected_orientation = possible_orientation # Wähle Orientierung als zu platzierende Orientierung aus\n",
    "                            break # Überprüfe keine weiteren Orientierungen\n",
    "\n",
    "                    else:\n",
    "                        # Wähle die Orientierung des potenziell zu platzierenden Packstücks als zu platzierendes Packstück\n",
    "                        selected_orientation = possible_orientation\n",
    "                        break # Überprüfe keine weiteren Orientierungen\n",
    "\n",
    "\n",
    "            # Prüfe ob es eine zulässige Orientierung gibt                \n",
    "            if len(selected_orientation) != 0:\n",
    "\n",
    "                # Füge dem Container das Packstück in der selektierten Orientierung hinzu\n",
    "                self.add_article(selected_orientation[0], selected_orientation[1], selected_orientation[2], selected_orientation[3], selected_orientation[4], selected_orientation[5], selected_orientation[6], selected_orientation[7], self.package_sequence_nr, selected_orientation[8])\n",
    "                self.package_sequence_nr += 1 # Erhöhe den Zähler für die Packstückreihenfolge um 1\n",
    "                self.packages_packed.append(article) # Erweitere die platzierten Packstücke\n",
    "                self.articles_in_raw.append(article) # Erweitere die in der Reihe platzierten Packstücke\n",
    "\n",
    "                raw_length_list.append(selected_orientation[2]) # Speichere die Packstücklänge in dem dafür vorgesehenen Array\n",
    "                main_box_width = main_box_width + selected_orientation[0] # Erhöhe die Breitenkoordinate\n",
    "                main_raw_width = main_raw_width - selected_orientation[0] # Verringere die verfügbare Reihenbreite\n",
    "                \n",
    "                # Aktualisiere die erlaubte Reihenlänge, falls noch kein Packstück in der Reihe platziert wurde\n",
    "                if len(self.articles_in_raw) == 1: \n",
    "                    main_raw_length = selected_orientation[2]\n",
    "                \n",
    "                # Für alle anderen Packstücke wird der entstehende Leerräume innerhalb der Reihe berechnet und befüllt. Hierbei werden Nebenreihen erzeugt.\n",
    "                elif len(self.articles_in_raw) > 1:\n",
    "                    if (main_raw_length - selected_orientation[2]) > 0: # Wenn freie Länge größer Null, dann rufe die Methode zur Befüllung des Leeraums auf\n",
    "                        \n",
    "                        side_raw_length = main_raw_length - selected_orientation[2] # Berechne die Länge des entstehenden Nebenleerraums\n",
    "                        side_raw_width = selected_orientation[0] # Die Breite des entstehenden Nebenleeraums entspricht der Breite des platzierten Packstücks\n",
    "                        side_box_length = main_box_length + selected_orientation[2] # Startposition für die Längenkoordinate vorgeben\n",
    "                        side_box_width = main_box_width - selected_orientation[0] # Startposition für Breitenkoordinate vorgeben \n",
    "                        side_box_height = main_box_height # Startposition für Höhenkoordinate vorgeben\n",
    "                        \n",
    "                        # Leerraum wird mit Nebenreihen befüllt\n",
    "                        raw_length_list = self.Add_Single_Layer (raw_length_list, side_raw_width, side_raw_length, side_box_width, side_box_length, side_box_height)\n",
    "        \n",
    "        # Entferne die platzierten Packstücke aus den verbleibenden Packstücken\n",
    "        self.remove_packed_articles_from_rest_packages()          \n",
    "                        \n",
    "        return raw_length_list         \n",
    "\n",
    "\n",
    "    def Add_Single_Layer (self, raw_length_list, side_raw_width, side_raw_length, side_box_width, side_box_length, side_box_height):\n",
    "             \n",
    "        initial_width = side_raw_width # Setze initiale Breitenkoordinate für Nebenleerraum\n",
    "        initial_pos_width = side_box_width # Setze initiale Breite für Nebenleerraum\n",
    "        \n",
    "        available_length = side_raw_length # Setze initiale Nebenleerraumlänge. Diese wird fortlaufend um die Länge der Nebenreihen reduziert.\n",
    "        \n",
    "        layer_completed = False # Variable, die als Abbruchkriterium für das Layer-Building fungiert. Kann keine weitere Nebenreihe erzeugt werden, wird diese auf True gesetzt.\n",
    "        \n",
    "        while layer_completed == False:\n",
    "            \n",
    "            # Generiere eine Liste, in der die Längen der Packstücke der Nebenreihen gespeichert werden.\n",
    "            # Diese ist notwendig, sofern ein Packstück die Nebenreihenlänge überschreitet.\n",
    "            side_length = []\n",
    "            \n",
    "            # Durchlaufe die verfügbaren Packstücke\n",
    "            for article in self.rest_packages:\n",
    "\n",
    "                selected_orientation = () # Initialisiere ein Tupel, in welches die Orientierung des potenziell zu platzierenden Packstücks gespeichert wird\n",
    "\n",
    "                for orientation in article: # Durchlaufe die Orientierungen eines Packstücks\n",
    "                    \n",
    "                    # Überprüfe ob das betrachtete Packstück in der betrachteten Orientierung platziert werden kann\n",
    "                    if (Check_Placement(article, self.articles_in_raw, self.container, self.max_weight, self.carried_weight, orientation, side_raw_width, side_raw_length, side_box_length, side_box_height, self.factor_overfilling) == True):\n",
    "        \n",
    "                        # Speichere die Daten über die Orientierung zwischen, welche potenziell platziert werden kann\n",
    "                        possible_orientation = (orientation[2], orientation[4], orientation[3], side_box_width, side_box_height, side_box_length, False, orientation[1], orientation[5])\n",
    "                        \n",
    "                        # Prüfe ob das Raw Building im Rahmen einer Stapelung durchgeführt wird\n",
    "                        if (self.call_from_stack_building == True):\n",
    "                            \n",
    "                            # Rufe Methode zur Prüfung der Überschreitung der maximalen Traglast auf\n",
    "                            # Übergebe: Orientierung, Packstücke der Stapelgrundfläche aus width_extension, Packstücke der Stapelgrundfläche aus length_extension, welche Gewichtzuweisung aller gepackten Packstücke enthält\n",
    "                            # Erhalte: Information, ob Platzierung zulässig\n",
    "                            placement_allowed = self.Check_Overload_Of_Artcicles(possible_orientation)\n",
    "                            \n",
    "                            if (placement_allowed == True): # Prüfe ob die Orientierung platziert werden darf\n",
    "                                selected_orientation = possible_orientation # Wähle Orientierung als zu platzierende Orientierung aus\n",
    "                                break # Überprüfe keine weiteren Orientierungen\n",
    "\n",
    "                        else:\n",
    "                            # Wähle die Orientierung des potenziell zu platzierenden Packstücks als zu platzierendes Packstück\n",
    "                            selected_orientation = possible_orientation\n",
    "                            break # Überprüfe keine weiteren Orientierungen\n",
    "\n",
    "\n",
    "                # Prüfe ob es eine zulässige Orientierung gibt                \n",
    "                if len(selected_orientation) != 0:\n",
    "                    \n",
    "                    if selected_orientation[2] > available_length: # Wenn Packstücke die Länge der Hauptreihe überschreitet, füge diese Länge der Liste hinzu\n",
    "                        length_to_add = side_box_length + selected_orientation[2]\n",
    "                        raw_length_list.append(length_to_add)\n",
    "\n",
    "                    self.add_article(selected_orientation[0],selected_orientation[1], selected_orientation[2], selected_orientation[3], selected_orientation[4], selected_orientation[5], selected_orientation[6], selected_orientation[7], self.package_sequence_nr, selected_orientation[8])\n",
    "                    self.package_sequence_nr += 1 # Erhöhe den Zähler für die Packstückreihenfolge um 1\n",
    "                    self.articles_in_raw.append(article) # Erweitere die in dem Nebenleerraum platzierten Packstücke\n",
    "                    self.packages_packed.append(article) # Erweitere die platzierten Packstücke\n",
    "                    side_length.append(selected_orientation[2]) # Füge die Länge des Packstücks in die Liste der Hauptreihenlänge hinzu\n",
    "                            \n",
    "                    side_raw_width = side_raw_width - selected_orientation[0] # Aktualisiere die verfügbare Breite der Nebenreibe\n",
    "                    side_box_width = side_box_width + selected_orientation[0] # Aktualisiere die Breitenkoordinate für nächstes Packstück\n",
    "                    \n",
    "                    # Platziere nächstes Packstück in der Nebenreihe\n",
    "            \n",
    "            if len(side_length) > 0:   # Reduziere die Länge der verfügbaren Schicht, falls eine Nebenreihe komplettiert wurde\n",
    "                available_length = available_length - max(side_length)\n",
    "            \n",
    "                # Setze die Länge der neuen Reihe auf die verfügbare Schichtlänge zurück. Aktualisere die Längenkoordinate für neue Nebenreihen.\n",
    "                side_raw_length = available_length \n",
    "                side_box_length = side_box_length + max(side_length)\n",
    "\n",
    "                # Setze verfügbare Breite für neue Nebenreihen zurück und setze die Breitenkoordinate zurück\n",
    "                side_raw_width = initial_width\n",
    "                side_box_width = initial_pos_width\n",
    "                \n",
    "            else:  # Wurde keine Packstücklänge in der Liste gespeichert, konnte auch keine weitere Nebenreihe erzeugt werden. Das Layer-Building gilt als abgeschlossen.\n",
    "                layer_completed = True \n",
    "                \n",
    "                \n",
    "        return raw_length_list\n",
    "\n",
    "\n",
    "\n",
    "    def Stack_Building (self, article_packed):\n",
    "            \n",
    "        # Füge alle Indexes der Packstücke, die als Basis für einen Stapel fungieren einer Liste hinzu. Hierüber wird später die Variable isStack auf True gesetzt\n",
    "        stack_indices = []\n",
    "\n",
    "        # Initialisiere Liste, welche durch die width_extension mit Tupeln befüllt wird, die alle Packstücke um die die Stapelfläche erweitert wurde enthalten. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "        # Zusätzlich wird dieser Liste ein Tupel des ersten Packstücks der Stapelfläche hinzugefügt\n",
    "        self.articles_from_width_extension = []\n",
    "        # Initialisiere Liste, welche durch die length_extension mit Tupeln befüllt wird, die alle Packstücke um die die Stapelfläche erweitert wurde enthalten. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "        self.articles_from_length_extension = []\n",
    "\n",
    "        # Initialisiere Variable um zu definieren, ob das die Add_One_Raw Funktion durch eine Stack Building Funktion aufgerufen wird\n",
    "        self.call_from_stack_building = True\n",
    "\n",
    "        # Packstücke auf einem Stapel werden nicht übersprungen\n",
    "        # change_sequence = False\n",
    "        \n",
    "        # Keine Überschreitung der Reihenlänge auf einem Stapel zugelassen\n",
    "        self.factor_overfilling = 1.0\n",
    "        \n",
    "        # Wenn ein Packstück noch nicht als Basis für einen Stapel fungierte (isStack = False), dann erzeuge die Stapelfläche\n",
    "        if article_packed.is_stack == False:\n",
    "            stack_indices.append(self.article_locations.index(article_packed)) # Füge den Packstückindex der entsprechenden Liste hinzu\n",
    "            stack_width = article_packed.width # Stapelbreite/Leerraumbreite entspricht der Breite des Packstücks\n",
    "            stack_height = article_packed.height # Stapelhöhe entspricht der Höhe des Packstücks\n",
    "            stack_length = article_packed.length # Stapellänge/Leerraumlänge entspricht der Breite des Packstücks\n",
    "            stack_box_width = article_packed.x # Breitenkoordindate entspricht der Breitenkoordinate des Packstücks\n",
    "            stack_box_height = article_packed.y + article_packed.height  # Höhenkoordindate entspricht der Höhenkoordinate des Packstücks zuzuglüch der Packstückhöhe \n",
    "            stack_box_length = article_packed.z # Längenkoordindate entspricht der Längenkoordinate des Packstücks\n",
    "            \n",
    "            # Füge Informationen des ersten Packstücks der Stapelfläche der Liste hinzu. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "            self.articles_from_width_extension.append((article_packed.package_ID, article_packed.width, article_packed.length, article_packed.x, article_packed.z))\n",
    "            \n",
    "            # Generiere größtmögliche Stapelbreite\n",
    "            stack_width, stack_length, stack_box_height, stack_indices = self.width_extension (stack_indices, stack_width, stack_length, stack_box_width, stack_box_length, stack_box_height)\n",
    "            # Generiere größtmögliche Stapellänge\n",
    "            stack_length, stack_indices = self.length_extension (stack_indices, stack_width, stack_length, stack_box_width, stack_box_length, stack_box_height)\n",
    "        \n",
    "            '''Führe Stapelvorgang durch'''\n",
    "            stack_layer_completed = False # Abbruchkriterium für das Stack-Building\n",
    "\n",
    "            stack_layer_length = stack_length # Initiale Leerraumlänge. Diese wird mit dem Platzieren von Hauptreihen auf dem Stapel fortlaufend reduziert.\n",
    "            initial_stack_width = stack_width # Initiale Leerraumbreite\n",
    "            initial_stack_box_width = stack_box_width # Initiale Breitenkoordinate auf dem Stapel\n",
    "\n",
    "            while stack_layer_completed == False:\n",
    "                \n",
    "                rest_packages_before_stacking = len(self.rest_packages) # Variable, welche der Anzahl an verbleibenden Packstücke entspricht.\n",
    "                \n",
    "                # Rufe Methode zur Bildung einer Reihe auf\n",
    "                stack_raw_length_list = self.Add_One_Raw(stack_width, stack_length, stack_box_width, stack_box_length, stack_box_height)\n",
    "                \n",
    "                # Wenn keine Packstücke platziert wurden, unterbreche das Stack-Building\n",
    "                if len(stack_raw_length_list) == 0: \n",
    "                    stack_layer_completed = True\n",
    "\n",
    "                else:\n",
    "                    stack_box_length = stack_box_length + max(stack_raw_length_list) # Neue Längenkoordinate entspricht alter Längenkoordindate zuzüglich der größten Packstücklänge der platzierten Reihe\n",
    "                    stack_box_width = initial_stack_box_width # Breitenkoordiante wird auf die initiale Breitenkoordinate gesetzt\n",
    "                    \n",
    "                    stack_layer_length = stack_layer_length - max(stack_raw_length_list) # Aktualisiere verfügbare Leerraumlänge\n",
    "                    stack_length = stack_layer_length # Neue initiale Reihenlänge entspricht der verfügbaren Leerraumlänge\n",
    "                    stack_width = initial_stack_width # Verfügbare Reihenbreite wird zurückgesetzt\n",
    "                    \n",
    "                # Setze die Variable IsStack auf True für Packstücke, die als Basis fungierten. Damit werden keine weiteren Packstücken auf diesen platziert.\n",
    "                if len(self.rest_packages) < rest_packages_before_stacking:\n",
    "                    for article_indice in stack_indices: # Durchlaufe hierzu die Indizes der Packstücke, die als Basis für den Stapel fungieren\n",
    "                        article_to_change = self.article_locations[article_indice] # Wähle das Packstück aus der Lösungskomponente\n",
    "                        # Setze nun die Variable isSTack auf True\n",
    "                        article_to_change.set_is_stack_to_true()\n",
    "            \n",
    "            '''Stapelung beendet'''\n",
    "                \n",
    "        return\n",
    "\n",
    "\n",
    "    def width_extension (self, stack_indices, stack_width, stack_length, stack_box_width, stack_box_length, stack_box_height):\n",
    "    \n",
    "        # Generiere größt mögliche Stapelbreite\n",
    "        extendible_in_width = True\n",
    "        while extendible_in_width == True:\n",
    "            stack_width_old = stack_width # Variable, die der Stapelbreite vor der Erweiterung entspricht\n",
    "            for article_to_extend in self.article_locations:\n",
    "                if ((article_to_extend.x >= stack_width + stack_box_width) and # Packstück muss größere Breitekoordinate als betrachtetes Packstück aufweisen\n",
    "                    (article_to_extend.x <= stack_width + stack_box_width + 5) and # Packstück muss in der Breite nahezu an den Stapel angrenzen\n",
    "                    (article_to_extend.z ==  stack_box_length) and # Packstück muss dieselbe Längenkoordinate aufweisen\n",
    "                    (article_to_extend.length <= stack_length + 5) and # Packstück muss in etwa diesselbe Länge aufweisen\n",
    "                    (article_to_extend.length >= stack_length - 5) and # Packstück muss in etwa diesselbe Länge aufweisen\n",
    "                    (article_to_extend.y + article_to_extend.height <= stack_box_height + 5) and  # Packstück muss in etwa diesselbe Höhe aufweisen\n",
    "                    (article_to_extend.y + article_to_extend.height >= stack_box_height - 5) and  # Packstück muss in etwa diesselbe Höhe aufweisen\n",
    "                    (article_to_extend.is_stack == False)): # Packstücke darf ebenso nicht als Basis für einen Stapel fungiert haben\n",
    "\n",
    "                        stack_width = stack_width + article_to_extend.width # Falls Bedingungen erfüllt sind, erweitere Stapelbreite\n",
    "                        \n",
    "                        # Falls das Packstück ein leicht größere Höhe aufweist, passe die Höhenkoordinate an\n",
    "                        if (article_to_extend.y + article_to_extend.height > stack_box_height):\n",
    "                            stack_box_height = article_to_extend.y + article_to_extend.height\n",
    "\n",
    "                        # Falls das Packstück ein kleinere Länge aufweist, passe die verfügbare Stapellänge an\n",
    "                        if stack_length < article_to_extend.length:\n",
    "                            stack_length = article_to_extend.length\n",
    "                        \n",
    "                        # Speichere den Index des Packstücks in einer Liste ab. Damit kann die Variable isStack nach dem Stapelvorgang auf True gesetzt werden\n",
    "                        stack_indices.append(self.article_locations.index(article_to_extend))\n",
    "\n",
    "                        # Füge Informationen der Liste hinzu, die alle Tupel der Packstücke um die die Stapelfläche erweitert wurde enthalten. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "                        self.articles_from_width_extension.append((article_to_extend.package_ID, article_to_extend.width, article_to_extend.length, article_to_extend.x, article_to_extend.z)) \n",
    "\n",
    "            # Terminiere, sofern die Stapelbreite nicht vergößert werden konnte\n",
    "            if stack_width == stack_width_old: \n",
    "                    extendible_in_width = False\n",
    "        \n",
    "        return stack_width, stack_length, stack_box_height, stack_indices\n",
    "\n",
    "\n",
    "    def length_extension (self, stack_indices, stack_width, stack_length, stack_box_width,stack_box_length,stack_box_height):        \n",
    "    \n",
    "        # Es muss eine Menge an Packstücken identifiziert werden, die über die gesamte Breite des Stapels angrenzt\n",
    "        # Weiterhin muss diese Menge an Packstücke über eine identische Länge verfügen\n",
    "        extendible_in_length = True\n",
    "        while extendible_in_length == True:\n",
    "            width_check = stack_box_width # Variable zur Überprüfung ob die Menge an Packstücken an die gesamte Breite des Stapels angrenzt\n",
    "            length_check = 0 # Variable zur Überprüfung ob die Menge an Packstücken über diesselbe Länge verfügen\n",
    "            width_extension = 0\n",
    "            LDU = 0 # Length Determining Unit: Packstück, welches die Länge der Erweiterung vorgibt\n",
    "\n",
    "            temporary_indices = [] # Liste zur Speicherung der temporären Packstück-Indexes\n",
    "\n",
    "            for article_to_extend in self.article_locations:\n",
    "                if ((article_to_extend.x == width_check) and # Es muss ein Packstück mit der selben Breitenkoordinate geben\n",
    "                    (article_to_extend.z >= stack_box_length + stack_length) and # Das Packstück muss in etwa in der Länge an den Stapel angrenzen\n",
    "                    (article_to_extend.z <= stack_box_length + stack_length + 5) and # Das Packstück muss in etwa in der Länge an den Stapel angrenzen\n",
    "                    (article_to_extend.y + article_to_extend.height <= stack_box_height + 5) and # Packstück muss in etwa diesselbe Höhe aufweisen\n",
    "                    (article_to_extend.y + article_to_extend.height >= stack_box_height - 5) and # Packstück muss in etwa diesselbe Höhe aufweisen\n",
    "                    (article_to_extend.is_stack == False)): # Das Packstück darf noch keine Basis eines Stapels darstellen\n",
    "\n",
    "                        # Das zuerst identifizierte Packstück gibt die Länge des Hilfsstapels vor\n",
    "                        if LDU == 0:\n",
    "                            length_check = article_to_extend.length\n",
    "                            LDU = 1\n",
    "\n",
    "                        # Weist das Packstück  ein passende Länge auf, wird der Hilftstapel erweitert\n",
    "                        if ((article_to_extend.length <= length_check + 5) and\n",
    "                            (article_to_extend.length >= length_check - 5)):\n",
    "\n",
    "                            width_check = width_check + article_to_extend.width # Erweitere die Breitenkoordinate des Hilfsstapels, damit weitere Packstücke zur Erweiterung in der Breite identifziert werden können\n",
    "                            width_extension = width_extension + article_to_extend.width # Erweitere die Breite des Hilfsstapels\n",
    "                            temporary_indices.append(self.article_locations.index(article_to_extend)) # Füge den Index den temporären Stapelindizes hinzu\n",
    "                            if article_to_extend.length > length_check: # Passe die Länge des Hilfsstapels an, sofern die Hilfsstapellänge durch das Packstück im Rahmen der Toleranz überschritten wird\n",
    "                                length_check = article_to_extend.length\n",
    "                            \n",
    "                            # Füge Informationen der Liste hinzu, die alle Tupel der Packstücke um die die Stapelfläche erweitert wurde enthalten. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "                            self.articles_from_length_extension.append((article_to_extend.package_ID, article_to_extend.width, article_to_extend.length, article_to_extend.x, article_to_extend.z)) \n",
    "\n",
    "            # Konnte eine Menge an Packstücke gefunden werden, welche über die gesamte Stapelbreite angrenzt, wird die endgültige Erweiterung der Stapelfläche durchgeführt\n",
    "            # Der Stapel wird dann um die Länge des Hilfsstapels erweitert\n",
    "            if ((width_extension >= stack_width - 5 )and \n",
    "                (width_extension <= stack_width + 5 )):\n",
    "                    stack_length = stack_length + length_check\n",
    "                    for indice in temporary_indices:\n",
    "                        stack_indices.append(indice)     \n",
    "            else: # Unterbreche, sofern die Breite des Hilfsstapels nicht der Breite des zu erweiternden Stapels entspricht\n",
    "                break\n",
    "            \n",
    "            # Wurde kein passendes Packstück identiziert, unterbreche die Erweiterung\n",
    "            if len(temporary_indices)==0:\n",
    "                break\n",
    "                        \n",
    "        return stack_length, stack_indices\n",
    "\n",
    "\n",
    "\n",
    "    def Create_Empty_Spaces(self, min_dimension):\n",
    "    \n",
    "        empty_space_pos_width = [] # Liste zur Speicherung der initialen Breitenposition aller Leerräume\n",
    "        empty_space_pos_length = [] # Liste zur Speicherung der initialen Längenposition aller Leerräume\n",
    "        empty_space_pos_height = 0 # Initiale Höhenposition der Leerräume = 0, da die Leerräume auf dem Boden des Containers gebildet werden\n",
    "        empty_space_width = [] # Liste zur Speicherung der Länge aller Leerräume\n",
    "        empty_space_length = [] # Liste zur Speicherung der Breite aller Leerräume\n",
    "        empty_space_height = self.container.height # Höhe aller Leerräume entspricht der Containerhöhe\n",
    "        empty_spaces = [] # Initialisierung Leerraumliste\n",
    "        \n",
    "        # Es wird eine Hilfsvariable definiert, welche der Längenposition einer Hauptreihe entspricht. Damit können Hauptreihen voneinander unterschieden werden.\n",
    "        current_length = 0\n",
    "        # Die erste Hauptreihe und damit auch der entsprechende reihenübergreifende Leeraum fangen bei der Längenposition 0 an\n",
    "        # Diese wird der entsprechenden Liste hinzugefügt\n",
    "        empty_space_pos_length.append(current_length)\n",
    "        \n",
    "        # Es wird eine Variable für die Anzahl der Haupreihen definiert\n",
    "        number_of_walls = 1 \n",
    "        \n",
    "        # Bestimme Anzahl an Walls. Für jede Wall wird ein reihenübergreifender Leeraum berechnet.\n",
    "        for article in self.article_locations:\n",
    "            if ((article.y == 0)and # Höhenposition = 0: Wall muss einen Boden haben\n",
    "                (article.x == 0)and # Breitenposition = 0: Wall muss einen Anfang haben\n",
    "                (article.z != current_length)): # Längenposition muss sich von der Längenposition des vorherigen Packstücks unterscheiden\n",
    "                number_of_walls = number_of_walls + 1 # Erhöhe Anzahl der Hauptreihen\n",
    "                current_length = article.z # Aktualsiere die Längenposition bzw. die Hilfsvariable\n",
    "                empty_space_pos_length.append(current_length) # Füge die Längenposition des Leerraums in die entsprechende Liste hinzu\n",
    "        \n",
    "        # Nun ist die Anzahl an Walls definiert. Weiterhin wurde für jeden reihenübergreifenden Leerraum dessen initiale Längenposition ermittelt.\n",
    "        # Nun soll die initiale Breitenposition errechnet und der entsprechenden Liste hinzugefügt werden\n",
    "        # Die initiale Breitenposition der reihenübergreifenden Leerräume entspricht dem Ende der Hauptreihen\n",
    "        # Durchlaufe hierzu die Packstücke aus denselben Hauptreihen\n",
    "        for i in range(number_of_walls):\n",
    "            column_end = 0 # Hilfsvariable column_end wird zur Berechnung der initialen Breitenposition pro Leerraum verwendet. Initialisierung auf 0 für jede Hauptreihe.\n",
    "            for article in self.article_locations:\n",
    "                if ((article.y == 0)and # Höhenposition des Packstücks muss 0 sein\n",
    "                    (article.z == empty_space_pos_length[i])and # Die Längenposition von Packstücken innerhalb einer Hauptreihe muss übereinstimmen\n",
    "                    (article.x + article.width > column_end)): # Existiert ein Packstück, welches das Ende der Hauptreihe in der Breite überschreitet?\n",
    "                        column_end = article.x + article.width # Falls ja, aktualisiere das Ende der Hauptreihenbreite\n",
    "            empty_space_pos_width.append(column_end)\n",
    "        \n",
    "        # Jetzt sind die Initialkoordinaten für sämtliche reihenübergreifende Leerräume definiert\n",
    "        # Als nächstes werden die Länge und Breite der Leerräume den entsprechenden Listen hinzugefügt\n",
    "        # Durchlaufe hierzu erneut die Hauptreihen\n",
    "        for i in range(number_of_walls):\n",
    "            \n",
    "            end = False # Hilfsvariable, welche angibt, ob das Ende eines Leerraums in der Länge erreicht ist\n",
    "            \n",
    "            # Verfügbare Leerraumbreite entspricht der Containerbreite abzüglich der initialen Breitenposition des Leerraums\n",
    "            space_width = self.container.width - empty_space_pos_width[i]\n",
    "            empty_space_width.append(space_width) # Füge die Breite des Leerraums in die entsprechende Liste hinzu\n",
    "            \n",
    "            # Bestimmen nun die maximale Leerraumlänge\n",
    "            # Durchlaufe hierzu die bereits platzierten Packstücke und schaue, ob ein Packstück den Leerraum in der Länge durchkreuzt\n",
    "            for article in self.article_locations:\n",
    "                if ((article.z > empty_space_pos_length[i]) and # Ein solches Packstück muss über eine größere initiale Längenposition als der Leerraum verfügen\n",
    "                    (article.y == 0 ) and #Ein solches Packstück muss sich auf dem Boden des Containers befinden\n",
    "                    (article.y + article.width > empty_space_pos_width[i])): # Ein solches Packstück muss den Leerraum in der Breite schneiden. Breitenpositon + Breite des Packstücks > Breitenposition des Leerraums\n",
    "                        space_length = article.z - empty_space_pos_length[i] # Falls ein Packstück durchkreuzt, errechnet sich die Leerraumlänge aus der Längenposition des identifzierten Packstücks abzüglich der intialen\n",
    "                                                                            # Längenposition des Leerraums\n",
    "                        empty_space_length.append(space_length) # Füge die Leerraumlänge der entsprechenden Liste hinzu\n",
    "                        end = True # Ende des Leeraums ist erreicht\n",
    "                        break\n",
    "            \n",
    "            # Wurde kein Packstück identifiziert, welches den Leerraum in der Länge durchkreuzt, so reicht die Leerrlänge bis zur Containerwand\n",
    "            if end == False:\n",
    "                space_length = self.container.length - empty_space_pos_length[i] # Leerraumlänge = Containerlänge - initiale Längenposition des Leerraums\n",
    "                empty_space_length.append(space_length) # Füge die Leerraumlänge der entsprechenden List hinzu\n",
    "        \n",
    "        # Füge die Leerräume mit den enstprechenden Informationen (Dimensionen, Koordianten) der Leerraumliste hinzu\n",
    "        for i in range(len(empty_space_pos_width)):\n",
    "                if ((empty_space_width[i] > min_dimension) and # Länge und Breite des Leerraums müssen größer sein als die minimale Packstückdimension\n",
    "                    (empty_space_length[i] > min_dimension)): \n",
    "                        empty_spaces.append((empty_space_width[i], empty_space_length[i], empty_space_height ,empty_space_pos_width[i], empty_space_pos_length[i], empty_space_pos_height))\n",
    "        \n",
    "        # Überprüfe ob es Schnittpunkte gibt\n",
    "        # Führe hierzu paarweise Vergleiche zwischen den Leerräumen durch\n",
    "        \n",
    "        abbruch = False # Hilfsvariable, die als Abbruchkriterium fungiert\n",
    "        while abbruch == False:\n",
    "            \n",
    "            length_empty_spaces_old = len(empty_spaces) # Hilfsvariable, welche der Anzahl an Leerräumen entspricht. Damit wird das Abbruchkriterium beeinflusst. \n",
    "            # Durchlaufe die Leerräume\n",
    "            for i in range(len(empty_spaces)-1):\n",
    "                # Prüfe zunächst, ob der betrachtete Leerraum in der Länge den darauffolgenden Leerraum durchkreuzt\n",
    "                if (empty_spaces[i][1] + empty_spaces[i][4] > empty_spaces[i+1][4]): # Es musss gelte: Längenposition des Leerraums + Länge des Leerraums > Längenposition des nächsten Leerraums\n",
    "                    # Falls Leerraum in der Längen durchkreuzt, prüfe welcher Leerraum die größere Grundfläche und damit das größere Volumen aufweist\n",
    "                    # Grundfläche errechnet durch Leerraumbreite * Leerraumlänge\n",
    "                \n",
    "                    # Entferne den nachfolgenden Leerraum, falls dieser eine kleinere Grundfläche als der betrachtete Leerraum aufweist\n",
    "                    if empty_spaces[i][0]*empty_spaces[i][1] > empty_spaces[i+1][0]*empty_spaces[i+1][1]: \n",
    "                        empty_spaces.remove(empty_spaces[i+1]) \n",
    "                        break\n",
    "                        \n",
    "                    # Bei Gleichstand: Selektiere den Leerraum mit der größeren Länge\n",
    "                    elif empty_spaces[i][0]*empty_spaces[i][1] == empty_spaces[i+1][0]*empty_spaces[i+1][1]:\n",
    "                        if empty_spaces[i][1] > empty_spaces[i+1][1]:\n",
    "                            empty_spaces.remove(empty_spaces[i+1])\n",
    "                            break\n",
    "                        else:\n",
    "                            empty_spaces.remove(empty_spaces[i])\n",
    "                            break\n",
    "                            \n",
    "                    # Entferne den betrachteten Leerraum, falls dieser eine kleinere Grundfläche als der nachfolgende Leerraum aufweist\n",
    "                    else:\n",
    "                        empty_spaces.remove(empty_spaces[i])\n",
    "                        break\n",
    "                        \n",
    "            # Unterbreche, falls keine weiteren Überschneidungen existieren\n",
    "            if len(empty_spaces) == length_empty_spaces_old:\n",
    "                abbruch = True\n",
    "                                    \n",
    "        return empty_spaces # Gebe sämtliche Leerräume zurück\n",
    "\n",
    "\n",
    "    def Modified_Stack_Building (self, article_packed):\n",
    "        global packplan\n",
    "        packplan = []\n",
    "        stack_indices = [] # Liste zur Speicherung der Indizes der Packstücke, die als Basis für den Stapel fungieren\n",
    "\n",
    "        # Initialisiere Liste, welche durch die width_extension mit Tupeln befüllt wird, die alle Packstücke um die die Stapelfläche erweitert wurde enthalten. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "        self.articles_from_width_extension = []\n",
    "        # Initialisiere Liste, welche durch die length_extension mit Tupeln befüllt wird, die alle Packstücke um die die Stapelfläche erweitert wurde enthalten. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "        self.articles_from_length_extension = []\n",
    "\n",
    "        if article_packed.is_stack == False:\n",
    "\n",
    "            stack_indices.append(self.article_locations.index(article_packed))\n",
    "            stack_width = article_packed.width # Stapelbreite entspricht der Breite des Packstücks\n",
    "            stack_height = article_packed.height # Stapelhöhe entspricht der Höhe des Packstücks\n",
    "            stack_length = article_packed.length # Stapellänge entspricht der Breite des Packstücks\n",
    "            stack_box_width = article_packed.x # Breitenkoordindate entspricht der Breitenkoordinate des Packstücks\n",
    "            stack_box_height = article_packed.y + article_packed.height  # Höhenkoordindate entspricht entspricht der Höhenkoordinate des Packstücks zuzuglüch der Packstückhöhe \n",
    "            stack_box_length = article_packed.z # Längenkoordindate entspricht der Längenkoordinate des Packstücks\n",
    "\n",
    "            # Füge Informationen des ersten Packstücks der Stapelfläche der Liste hinzu. Tupel: (Packstück ID, Packstück Breite, Packstück Länge, Packstück Breitenkoordinate, Packstück Längenkoordinate)\n",
    "            self.articles_from_width_extension.append((article_packed.package_ID, article_packed.width, article_packed.length, article_packed.x, article_packed.z))\n",
    "\n",
    "            # Generiere größtmögliche Stapelbreite\n",
    "            stack_width, stack_length, stack_box_height, stack_indices = self.width_extension (stack_indices, stack_width, stack_length, stack_box_width, stack_box_length, stack_box_height)\n",
    "            # Generiere größtmögliche Stapellänge\n",
    "            stack_length, stack_indices = self.length_extension (stack_indices, stack_width, stack_length, stack_box_width, stack_box_length, stack_box_height)\n",
    "\n",
    "            # Führe Stapelvorgang durch. Jetzt jedoch mit zugelassenen Überhängen.\n",
    "            stack_completed = False\n",
    "            while stack_completed == False:\n",
    "\n",
    "                stack_raws = []  # Liste zur Speicherung der platzierten Packstücke\n",
    "                stack_raw_length_list = []  # Liste zur Speicherung der Längen platzierter Packstücke\n",
    "    \n",
    "                stack_raw_width = stack_width  # Initiale Stapelbreite bzw. Breite des Leerraums\n",
    "                \n",
    "                # Durchlaufe die verbleibenden Packstücke\n",
    "                for article_to_pack in self.rest_packages:                  \n",
    "                    selected_orientation = () # Initialisiere ein Tupel, in welches die Orientierung des potenziell zu platzierenden Packstücks gespeichert wird\n",
    "                    for orientation in article_to_pack: # Durchlaufe die möglichen Orientierungen eines Packstücks (sortiert nach größtmöglicher Grundfläche)\n",
    "\n",
    "                        # Prüfe ob das Packstück auf den Stapel passt & keine anderen Packstücke überschneidet\n",
    "                        if (Check_Placement_Modified_Stacking (self.container, self.max_weight, self.carried_weight, self.article_locations, orientation, stack_raw_width, stack_length, stack_box_length, stack_box_height, stack_box_width) == True):\n",
    "\n",
    "                            # Falls  Bedingungen eingehalten werden, füge Orientierung der Liste hizu\n",
    "                            possible_orientation = (orientation[2], orientation[4], orientation[3], stack_box_width, stack_box_height , stack_box_length, False, orientation[1], orientation[5])\n",
    "                            \n",
    "                            # Rufe Methode zur Prüfung der Überschreitung der maximalen Traglast auf\n",
    "                            # Übergebe: Orientierung, Packstücke der Stapelgrundfläche aus width_extension, Packstücke der Stapelgrundfläche aus length_extension, welche Gewichtzuweisung aller gepackten Packstücke enthält\n",
    "                            # Erhalte: Information, ob Platzierung zulässig\n",
    "                            placement_allowed = self.Check_Overload_Of_Artcicles(possible_orientation)\n",
    "\n",
    "                            if (placement_allowed == True): # Prüfe ob die Orientierung platziert werden darf\n",
    "                                selected_orientation = possible_orientation # Wähle Orientierung als zu platzierende Orientierung aus\n",
    "                                break # Überprüfe keine weiteren Orientierungen\n",
    "\n",
    "                    # Prüfe ob es eine zulässige Orientierung gibt\n",
    "                    if len(selected_orientation) != 0:\n",
    "\n",
    "                        # Erweitere die Lösungskomponente\n",
    "                        self.add_article(selected_orientation[0],selected_orientation[1], selected_orientation[2], selected_orientation[3], selected_orientation[4], selected_orientation[5], \n",
    "                                                    selected_orientation[6], selected_orientation[7], self.package_sequence_nr, selected_orientation[8])\n",
    "                        self.package_sequence_nr += 1\n",
    "                        self.packages_packed.append(article_to_pack) # Erweitere die gepackten Packstücke\n",
    "                        stack_raws.append(article_to_pack) # Erweitere die Packstückliste des Stapels \n",
    "\n",
    "                        stack_raw_length_list.append(selected_orientation[2])  # Füge die Packstücklänge in die entsprechende Liste hinzu\n",
    "                        stack_raw_width = stack_raw_width - selected_orientation[0] # Reduziere die verfügbare Reihenbreite\n",
    "                        stack_box_width = stack_box_width + selected_orientation[0] # Akualsiere die Breitenkoordinate\n",
    "                \n",
    "                # Entferne die auf dem Stapel platzierten Packstücke von den verbleibenden Packstücken\n",
    "                for article_to_remove in stack_raws:\n",
    "                    self.rest_packages.remove(article_to_remove)\n",
    "\n",
    "                # Setze die Variable IsStack auf True für Packstücke, die als Basis fungierten. Damit werden keine weiteren Packstücken auf diesen platziert.\n",
    "                if len(stack_raws) > 0:\n",
    "                    for article_indice in stack_indices:\n",
    "                        article_to_change = self.article_locations[article_indice]\n",
    "                        article_to_change.set_is_stack_to_true()\n",
    "                \n",
    "                # Falls keine Packstücke auf dem Stapel platziert wurden, unterbreche das Modified Stack-Building\n",
    "                if len(stack_raws) == 0: \n",
    "                    stack_completed = True\n",
    "                else: # Falls doch, passe die Längenkoordinate, die Breitenkoordinate und die Leerraumlänge an\n",
    "                    stack_box_length = stack_box_length + max(stack_raw_length_list)\n",
    "                    stack_box_width = article_packed.x\n",
    "                    stack_length = stack_length - max(stack_raw_length_list)\n",
    "\n",
    "        for artloc in self.article_locations:\n",
    "            packplan_package = [artloc.width, artloc.height, artloc.length, artloc.x, artloc.y, artloc.z, artloc.is_stack, artloc.package_ID, artloc.package_sequence_nr, artloc.package_weight]\n",
    "            packplan.append(packplan_package)\n",
    "   \n",
    "    ''' Ende Funktionen des Single Knapsack Algortihmus'''\n",
    "\n",
    "\n",
    "\n",
    "    '''Funktionen zur Visualisierung'''\n",
    "    def get_lineset(self, offset_x=0, offset_y=0, offset_z=0):\n",
    "        points = [[0+offset_x, 0+offset_y, 0+offset_z],\n",
    "                  [self.container.width+offset_x, 0+offset_y, 0+offset_z],\n",
    "                  [0+offset_x, self.container.height+offset_y, 0+offset_z],\n",
    "                  [self.container.width+offset_x, self.container.height+offset_y, 0+offset_z],\n",
    "                  [0+offset_x, 0+offset_y, self.container.length+offset_z],\n",
    "                  [self.container.width+offset_x, 0+offset_y, self.container.length+offset_z],\n",
    "                  [0+offset_x, self.container.height+offset_y, self.container.length+offset_z],\n",
    "                  [self.container.width+offset_x, self.container.height+offset_y, self.container.length+offset_z]]\n",
    "\n",
    "        lines = [[0, 1], [0, 2], [1, 3], [2, 3], [4, 5], [4, 6], [5, 7], [6, 7], [0, 4], [1, 5], [2, 6], [3, 7]]\n",
    "        colors = [[0, 0, 0] for i in range(len(lines))]\n",
    "\n",
    "        line_set = o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(points), lines=o3d.utility.Vector2iVector(lines))\n",
    "        line_set.colors = o3d.utility.Vector3dVector(colors)    \n",
    "        return line_set\n",
    "\n",
    "    def save_packplan(self):\n",
    "        print(\"Packplan\")\n",
    "        self.timestamp = datetime.now().strftime(\"%Y-%m-%d %Hh%Mm%Ss\")\n",
    "        file_path_packplan = 'Simulationen//' + str(self.timestamp) + ' BI01' + ' Simulation Packplan.csv'\n",
    "        pckpln = []\n",
    "        for artloc in self.article_locations:\n",
    "            print(artloc.width, artloc.height, artloc.length, artloc.x, artloc.y, artloc.z, artloc.package_weight)\n",
    "            package = [artloc.width, artloc.height, artloc.length, artloc.x, artloc.y, artloc.z, artloc.is_stack, artloc.package_ID, artloc.package_sequence_nr, artloc.package_weight]\n",
    "            pckpln.append(package)\n",
    "        results_packplan = pd.DataFrame(pckpln)\n",
    "        pckpln = []\n",
    "        results_packplan.to_csv(path_or_buf=file_path_packplan, header=False, index=False)\n",
    "\n",
    "    def save_container(self):\n",
    "        self.timestamp = datetime.now().strftime(\"%Y-%m-%d %Hh%Mm%Ss\")\n",
    "        file_path_container = 'Simulationen//' + str(self.timestamp) + ' BI01' + ' Simulation Container.csv'\n",
    "        container = []\n",
    "        print(self.container[0], self.container[1], self.container[2])\n",
    "        cntnr = [self.container[0], self.container[1], self.container[2]]\n",
    "        container.append(cntnr)\n",
    "        results_container = pd.DataFrame(container)\n",
    "        container = []\n",
    "        results_container.to_csv(path_or_buf=file_path_container, header=False, index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    def get_geometry(self, offset_x=0, offset_y=0, offset_z=0):\n",
    "        line_set=self.get_lineset(offset_x, offset_y, offset_z)\n",
    "        \n",
    "        geo_list=[line_set]\n",
    "        for artloc in self.article_locations:\n",
    "            mesh_box = o3d.geometry.TriangleMesh.create_box(width=artloc.width, height=artloc.height, depth=artloc.length)\n",
    "            mesh_box.translate(np.array([artloc.x+offset_x,artloc.y+offset_y,artloc.z+offset_z]))   \n",
    "            mesh_box.compute_vertex_normals()\n",
    "\n",
    "            rvalue=random.random()\n",
    "            mesh_box.paint_uniform_color([rvalue, 1-rvalue, random.random()])    \n",
    "            geo_list.append(mesh_box)\n",
    "        return geo_list\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.container) + \"\\n    \" + \"\\n    \".join(str(x) for x in self.article_locations)\n",
    "    '''Ende Funktionen zur Visualisierung'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Solution (=Individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    \n",
    "    def __init__(self, modified_order_data, container_data):\n",
    "        self.containers=[] # Liste der Container, aus der die Lösung besteht\n",
    "        self.container_number = 0 # Anzahl der Container, aus der die Lösung besteht\n",
    "        self.usage_average = 0 # durschnittliche Containerauslastung der Lösung\n",
    "        self.costs = 0 # Summe der Kosten aller Container in der Lösung\n",
    "\n",
    "        # Variablen des Greedy Verfahrens\n",
    "        self.modified_order_data = modified_order_data\n",
    "        self.container_data = container_data\n",
    "\n",
    "        self.packages_packed_list = [] # Liste in der die platzierten Packstücke aller Containertypen abgespeichert werden\n",
    "        self.container_to_add_list = [] # Liste in der die einzelnen Lösungskomponenten bzw. Instanzen abgespeichert werden\n",
    "        self.usage_list = [] # Liste in der die Auslastungen aller Containertypen abgespeichert werden\n",
    "\n",
    "        self.index_selected_container = 0 # Index des gewählten Containers\n",
    "        self.usage_selected = 0 # Volumenauslastung des gewählten Containers\n",
    "\n",
    "\n",
    "    # Füge einen übergebenen Container der Lösung hinzu\n",
    "    def add_container(self, container):\n",
    "        self.containers.append(container) # Füge Container der Lösung hinzu\n",
    "        self.costs += container.costs # Erhöhe die Kosten der Lösung\n",
    "        self.container_number += 1 # Erhöhe die Anzahl der Container in der Lösung\n",
    "\n",
    "    # Berechne die durschnittliche Volumenauslastung der Lösung\n",
    "    def set_usage_average(self):\n",
    "        usage_total = 0 # Initialisieren Volumenauslastung\n",
    "\n",
    "        for container in self.containers:\n",
    "            usage_total += container.volume_usage_rate # Summiere Volumenauslastung aller Container in der Lösung auf\n",
    "        \n",
    "        self.usage_average = usage_total/len(self.containers) # Teile Summe durch Containeranzahl\n",
    "\n",
    "    '''Funktionen für das Greedy Verfahren'''\n",
    "    def calculate_solution (self):\n",
    "        # Packe einen neuen Container, solange verbleibende Packstücke existieren\n",
    "        while len(self.modified_order_data) > 0:\n",
    "\n",
    "            \n",
    "            # Entferne die Daten aus den Listen\n",
    "            self.packages_packed_list = []\n",
    "            self.container_to_add_list = []\n",
    "            self.usage_list = []\n",
    "\n",
    "            # Wende den SKA auf jeden Container-Typ an\n",
    "            global rest_packages\n",
    "            rest_packages = self.pack_each_container_type()\n",
    "\n",
    "            # Nun liegen die Ergebnisse für jeden Containertyp vor\n",
    "            # Das Greedy-Verfahren selektiert nun den Containertyp mit der höchsten Volumenauslastung\n",
    "            self.index_selected_container = self.usage_list.index(max(self.usage_list)) # Index des Containertyps mit der höchsten Volumenauslastung, bei mehreren gleichen Werten wählt max() in Python den Index des ersten Wertes\n",
    "            self.usage_selected = self.usage_list[self.index_selected_container] # Auslastung des Containertyps mit der höchsten Volumenauslastung\n",
    "\n",
    "            \n",
    "            # Prüfe, ob mehrere Container mit der selben Auslastung existieren, falls ja: wähle den größeren\n",
    "            self.check_for_same_volume_usage_and_select_bigger()\n",
    "                             \n",
    "            # Prüfe, ob es ein Container existiert, welcher alle verbleibenden Packstücke packt und wähle diesen falls die in der Funktion beschriebenen Voraussetzungen erfüllt sind\n",
    "            self.last_container_optimization(rest_packages)\n",
    "                \n",
    "            # Selektiere nun die Lösungskomponente, die gepackten Packstücke, die Containerauslastung und das gepackte Gewicht\n",
    "            packages_packed_selected = self.packages_packed_list [self.index_selected_container]\n",
    "            container_to_add_selected = self.container_to_add_list [self.index_selected_container]\n",
    "            self.usage_selected = self.usage_list [self.index_selected_container]\n",
    "            \n",
    "            # Füge die Lösungskomponente der Lösung hinzu\n",
    "            self.add_container(container_to_add_selected)\n",
    "\n",
    "            # Die Packstücke welcher in der selektierten Instanz gepackt wurden, müssen aus modifizierten Bestelldaten entfernt werden\n",
    "            for package in packages_packed_selected:\n",
    "                self.modified_order_data.remove(package)\n",
    "        \n",
    "        # Errechne die durchschnittliche Containerauslastung der Lösung\n",
    "        self.set_usage_average()\n",
    "\n",
    "\n",
    "\n",
    "    # Prüfe, ob mehrere Container mit der selben Auslastung existieren, falls ja: wähle den größeren\n",
    "    def check_for_same_volume_usage_and_select_bigger(self):\n",
    "        # Durchlaufe dazu die Liste mit den gespeicherten Containerauslastungen\n",
    "        for index in range(len(self.usage_list)):\n",
    "            if self.usage_list[index] == (self.usage_selected): # Überprüfe für jeden Container, ob er die selbe Auslastung hat, wie der Container mit der höchsten Auslastung\n",
    "                if (self.container_to_add_list[index].container.width * self.container_to_add_list[index].container.height * self.container_to_add_list[index].container.length) > \\\n",
    "                    (self.container_to_add_list[self.index_selected_container].container.width * self.container_to_add_list[self.index_selected_container].container.height * self.container_to_add_list[self.index_selected_container].container.length): # Überprüfe bei gleicher Auslastung, ob der bisher selektierte Container kleiner ist\n",
    "                    self.index_selected_container = index # Ändere den Index des selektierten Containers, falls der bisher selektierte kleiner war\n",
    "                    self.usage_selected = self.usage_list[self.index_selected_container] # Ändere die Auslastung des selektierten Containers\n",
    "\n",
    "\n",
    "    # Wende den SKA auf jeden Container-Typ an\n",
    "    def pack_each_container_type(self):\n",
    "        global rest_packages\n",
    "        for container_type in self.container_data:\n",
    "            global rest_packages\n",
    "\n",
    "            # Sicherstellung, dass jedem Containertyp diesselben Packstücke übergeben werden\n",
    "            rest_packages = [package for package in self.modified_order_data]\n",
    "            \n",
    "            # Anwendung SKA zur Generierung einer Lösungskomponente\n",
    "            container_to_add = Container(container_type[0], container_type[2], container_type[1], container_type[3], container_type[4], rest_packages)\n",
    "            packages_packed = container_to_add.pack_container()\n",
    "\n",
    "            container_to_add.set_volume_usage_rate()# Berechne Containerauslastungsrate der Lösungskomponente\n",
    "\n",
    "            # Füge die Ergebnisse für den betrachteten Containertyp den erzeugten Listen hinzu\n",
    "            # Aber nur, falls mindestens ein Packstück platziert wurde\n",
    "            if container_to_add.volume_used != 0:\n",
    "                \n",
    "                self.packages_packed_list.append(packages_packed) # Erweitere die Liste in der die platzierten Packstücke aller Containertypen abgespeichert werden\n",
    "                self.container_to_add_list.append(container_to_add) # Erweitere die Liste in der die einzelnen Lösungskomponenten bzw. Instanzen abgespeichert werden\n",
    "                self.usage_list.append(container_to_add.volume_usage_rate) # Erweitere die Liste in der die Auslastungen aller Containertypen abgespeichert werden\n",
    "\n",
    "        return rest_packages\n",
    "    \n",
    "    # Prüft, ob es ein Container existiert, welcher alle verbleibenden Packstücke packt und wählt diesen falls die in der Funktion beschriebenen Voraussetzungen erfüllt sind\n",
    "    def last_container_optimization(self, rest_packages):\n",
    "            \n",
    "            # Prüfe zunächst, ob Container existieren, welche alle restlichen Packstücke packen & ermittle daraus den Container mit der höchsten Auslastung\n",
    "            container_rest_packages_volume_usage_rate = 0 # Initialisiere die Auslastung des Container, der alle restlichen Packstücke packt\n",
    "            for index, container_packages in enumerate(self.packages_packed_list):\n",
    "                if (len(container_packages) == len(self.modified_order_data)) and (self.container_to_add_list[self.index_selected_container].volume_usage_rate > container_rest_packages_volume_usage_rate):\n",
    "                    container_rest_packages_volume_usage_rate = self.container_to_add_list[index].volume_usage_rate # Auslastung des Containers der alle restlichen packstücke packt & die höchste Auslastung hat\n",
    "                    index_container_all_rest_packages = index # Index des Containers der alle restlichen packstücke packt & die höchste Auslastung hat\n",
    "\n",
    "                    # Es gibt einen Container, der alle restlichen Packstücke packt\n",
    "\n",
    "                    # Berechne das Volumen der nicht durch den aktuell selektierten Container gepackten Packstücke\n",
    "                    remaining_articles = [article for article in rest_packages if article not in self.packages_packed_list [self.index_selected_container]] # Erzeuge eine Liste, die alle Packstücke enthält die durch den selektierten Container nicht gepackt wurden\n",
    "                    volume_of_remaining_articles = 0 # Initialisiere das Gesamtvolumen der nicht gepackten Packstücke\n",
    "                    for article in remaining_articles:\n",
    "                        volume_of_remaining_articles += article[0][6] # Summiere die Volumen der Packstücke\n",
    "\n",
    "                \n",
    "                    # Nun wird ermittelt, ob der Container der alle restlichen Packstücke anstatt dem bisher selektierten Container verwendet werden soll\n",
    "                    # Prüfe, ob es einen Containertypen gibt, der alle restlichen Packstücke tragen kann & dessen Ausalstung verrechnet mit dem aktuell selektierten Container im Mittel höher ist, als die Auslastung des Containers, der alle restlichen Packstücke packen kann\n",
    "                    use_container_all_rest_packages = True # Initialisiere die Verwendung des Containers der alle restlichen Packstücke packt mit True\n",
    "                    for container in self.container_data:\n",
    "                        container_volume = container[0]*container[1]*container[2]/1000\n",
    "\n",
    "                        # Prüfe, ob der Conrtainertyp ein größeres Volumen als alle restlichen Packstücke hat & ob die durchschnittliche Auslastung aus dem bisher selektierten Container und dem nächsten Container (befüllt mit allen Restartikeln) größer ist, als die Auslastung des Containers, der alle restlichen Packstücke packt\n",
    "                        if volume_of_remaining_articles/container_volume < 1 and \\\n",
    "                            (self.container_to_add_list[self.index_selected_container].volume_usage_rate + volume_of_remaining_articles/container_volume) / 2 > self.container_to_add_list[index_container_all_rest_packages].volume_usage_rate:\n",
    "                            # Trifft die beiden Bedingungen zu soll der Container der alle restlichen Packstücke tragen kann nicht verwendet werden\n",
    "                            use_container_all_rest_packages = False\n",
    "\n",
    "                    if (use_container_all_rest_packages): # Prüfe, ob der Container der alle restlichen Packstücke tragen kann verwendet werden soll\n",
    "                        self.index_selected_container = index_container_all_rest_packages # Verwende den Container, der alle restlichen Packstücke packt als Lösungskomponente\n",
    "    '''Ende der Funktionen für das Greedy Verfahren'''\n",
    "    def print_packplan(self):\n",
    "        for container in self.containers:\n",
    "            container.save_packplan()\n",
    "            container.save_container()\n",
    "            \n",
    "    # Visualisiere die Container in der Lösung\n",
    "    def visualize(self):\n",
    "        vis = o3d.visualization.Visualizer()\n",
    "        vis.create_window()\n",
    "        offset_x=0\n",
    "        offset_x_delta=100\n",
    "        for container in self.containers:\n",
    "            for geo in container.get_geometry(offset_x=offset_x):\n",
    "                vis.add_geometry(geo)\n",
    "            \n",
    "            offset_x+=offset_x_delta\n",
    "            offset_x+=container.container.width\n",
    "\n",
    "        o3d.visualization.ViewControl.set_zoom(vis.get_view_control(), 0.8)\n",
    "        vis.run()\n",
    "        vis.destroy_window()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \n",
    "\n",
    "        return \"packing solution\\n  \" + \"\\n  \".join(str(x) for x in self.containers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Population():\n",
    "\n",
    "    def __init__(self, number_of_parents, population_size, parent_solutions, choosen_parent_pairing):\n",
    "        self.pack_orders = [] # Liste in die alle Genome einer Population als Liste gespeichert werden\n",
    "        self.mps_datasets = [] # Liste in der alle modifizierten Bestelldatensätze einer Population gespeichert werden\n",
    "        self.parent_solutions = parent_solutions # Liste mit allen Lösungen der Populationseltern\n",
    "        self.population_solutions = [] # Liste mit allen Lösungen der Population\n",
    "        self.list_of_parent_pairs_for_crossover = [] # Liste mit Tupel für jedes Elternpaar, Tupel enthält nur Index des Elternteils\n",
    "        self.number_of_parents = number_of_parents # Anzahl an Elternindividuen, die für den Crossover zu berücksichtigen sind\n",
    "        self.population_size = population_size # Startpopulationsgröße\n",
    "        self.choosen_parent_pairing = choosen_parent_pairing # Index für gewähltes Elternselektionsverfahren\n",
    "\n",
    "    def add_pack_order(self, pack_order):\n",
    "        self.pack_orders.append(pack_order)\n",
    "\n",
    "    def add_mps_dataset(self, mps_dataset):\n",
    "        self.mps_datasets.append(mps_dataset)\n",
    "\n",
    "    def add_population_solution(self, solution):\n",
    "        self.population_solutions.append(solution)\n",
    "\n",
    "    def sort_population_solutions(self):\n",
    "        self.population_solutions.sort(key = lambda solution: solution.usage_average, reverse = True) # Sortiere die Lösungen nach Volumenauslastung (größte Auslastung am Anfang der Liste)\n",
    "\n",
    "    # Entferne alle Eltern, die nicht für die Rekombination berücksichtigt werden sollen\n",
    "    def ceep_parents_for_pairing(self):\n",
    "        self.parent_solutions = self.parent_solutions[:self.number_of_parents]\n",
    "\n",
    "\n",
    "    '''Funktionen für die Berechnung der Elternpaarzuweisung'''\n",
    "    # Bilde die Elternpaare für den Crossover anhand des ausgewählten Verfahrens\n",
    "    def create_parent_pairs(self):\n",
    "        if (self.choosen_parent_pairing == 0):\n",
    "            self.get_parent_pairs_first_with_last()\n",
    "        elif (self.choosen_parent_pairing == 1):\n",
    "            self.get_parent_pairs_first_with_last_step_2()\n",
    "        elif (self.choosen_parent_pairing == 2):\n",
    "            self.get_parent_pairs_last_with_first()\n",
    "        elif (self.choosen_parent_pairing == 3):\n",
    "            self.get_parent_pairs_first_with_second()\n",
    "        elif (self.choosen_parent_pairing == 4):\n",
    "            self.get_parent_pairs_first_with_better_half()\n",
    "        elif (self.choosen_parent_pairing == 5):\n",
    "            self.get_parent_pairs_better_half_with_first()\n",
    "\n",
    "\n",
    "    # Funktion zur Erzeugungvon Elternpaaren (nFWL) für den Crossover: Bester mit Schlechtestem, Zweitbester mit Zweitschlechtestem...\n",
    "    def get_parent_pairs_first_with_last(self):\n",
    "\n",
    "        # Initialisiere Zählervariable für die Auswahl des Elternteils A bzw. B\n",
    "        parent_A = 0\n",
    "        parent_B = 0\n",
    "        # Initialisiere Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "        parent_counter = 0\n",
    "\n",
    "        while (parent_counter < self.number_of_parents/2): # Überprüfe, ob bereits alle Eltern berücksichtigt wurden\n",
    "            parent_A = parent_counter # Weise Index für Elternteil A zu (Starte am Anfang der Liste mit allen Individuen)\n",
    "            if ((self.number_of_parents%2 == 1) and ((self.number_of_parents-1)/2 == parent_counter)): # Überprüfe ob die Populationsgröße ungerade ist und alle Elternteile bis auf einen (den Mittleren) bereits berücksichtigt wurden\n",
    "                parent_B = 0 # Weiße Index für Elternteil B zu: erstes Elternteil der Population\n",
    "            else:\n",
    "                parent_B = (self.number_of_parents - 1 - parent_counter) # Weise Index für Elternteil B zu (Starte am Ende der Liste mit allen Individuen)\n",
    "            \n",
    "            \n",
    "            self.list_of_parent_pairs_for_crossover.append((parent_A, parent_B)) # Füger das erzeugte Elternpaar der Liste hinzu, welche alle Elternpaare enthält die miteinander rekombiniert werden sollen\n",
    "            parent_counter += 1 # Erhöhe Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "\n",
    "\n",
    "    # Funktion zur Erzeugungvon Elternpaaren (nFWLS2) für den Crossover: Bester mit Schlechtestem, Drittbester mit Drittschlechtestem...\n",
    "    def get_parent_pairs_first_with_last_step_2(self):\n",
    "\n",
    "        # Initialisiere Zählervariable für die Auswahl des Elternteils A bzw. B\n",
    "        parent_A = 0\n",
    "        parent_B = 0\n",
    "        # Initialisiere Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "        parent_counter = 0\n",
    "\n",
    "        while (parent_counter < self.number_of_parents): # Überprüfe, ob bereits alle Eltern berücksichtigt wurden\n",
    "\n",
    "            parent_A = parent_counter # Weise Index für Elternteil A zu (Starte am Anfang der Liste mit allen Individuen)\n",
    "\n",
    "            if ((self.number_of_parents%2 == 1) and ((self.number_of_parents-1)/2 == parent_counter)): # Überprüfe ob die Populationsgröße ungerade ist und alle Elternteile bis auf einen (den Mittleren) bereits berücksichtigt wurden\n",
    "                parent_B = 0 # Weiße Index für Elternteil B zu: erstes Elternteil der Population\n",
    "            else:\n",
    "                parent_B = (self.number_of_parents - 1 - parent_counter) # Weise Index für Elternteil B zu (Starte am Ende der Liste mit allen Individuen)\n",
    "            \n",
    "            \n",
    "            self.list_of_parent_pairs_for_crossover.append((parent_A, parent_B)) # Füger das erzeugte Elternpaar der Liste hinzu, welche alle Elternpaare enthält die miteinander rekombiniert werden sollen\n",
    "            parent_counter += 2 # Erhöhe Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "\n",
    "    # Funktion zur Erzeugungvon Elternpaaren (LWF) für den Crossover: Schlechtester mit Bestem, Zweitschlechtester mit Zweitbestem...\n",
    "    def get_parent_pairs_last_with_first(self):\n",
    "\n",
    "        # Initialisiere Zählervariable für die Auswahl des Elternteils A bzw. B\n",
    "        parent_A = 0\n",
    "        parent_B = 0\n",
    "        # Initialisiere Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "        parent_counter = 0\n",
    "\n",
    "        while (parent_counter < self.number_of_parents/2): # Überprüfe, ob bereits alle Eltern berücksichtigt wurden\n",
    "\n",
    "            parent_A = parent_counter # Weise Index für Elternteil A zu (Starte am Anfang der Liste mit allen Individuen)\n",
    "\n",
    "            if ((self.number_of_parents%2 == 1) and ((self.number_of_parents-1)/2 == parent_counter)): # Überprüfe ob die Populationsgröße ungerade ist und alle Elternteile bis auf einen (den Mittleren) bereits berücksichtigt wurden\n",
    "                parent_B = 0 # Weiße Index für Elternteil B zu: erstes Elternteil der Population\n",
    "            else:\n",
    "                parent_B = (self.number_of_parents - 1 - parent_counter) # Weise Index für Elternteil B zu (Starte am Ende der Liste mit allen Individuen)\n",
    "            \n",
    "            \n",
    "            self.list_of_parent_pairs_for_crossover.append((parent_B, parent_A)) # Füger das erzeugte Elternpaar der Liste hinzu, welche alle Elternpaare enthält die miteinander rekombiniert werden sollen\n",
    "            parent_counter += 1 # Erhöhe Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "        \n",
    "\n",
    "    # Funktion zur Erzeugungvon Elternpaaren (TNB) für den Crossover: Bester mit Zweitbestem, Drittbester mit Viertbestem...\n",
    "    def get_parent_pairs_first_with_second(self):\n",
    "\n",
    "        # Initialisiere Zählervariable für die Auswahl des Elternteils A bzw. B\n",
    "        parent_A = 0\n",
    "        parent_B = 0\n",
    "        # Initialisiere Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "        parent_counter = 0\n",
    "\n",
    "        while (parent_counter < self.number_of_parents): # Überprüfe, ob bereits alle Eltern berücksichtigt wurden\n",
    "\n",
    "            parent_A = parent_counter # Weise Index für Elternteil A zu (Starte am Anfang der Liste mit allen Individuen)\n",
    "\n",
    "            if ((self.number_of_parents%2 == 1) and (parent_counter == self.number_of_parents - 1)): # Überprüfe ob die Populationsgröße ungerade ist und alle Elternteile bis auf einen (den Letzten) bereits berücksichtigt wurden\n",
    "                parent_B = 0 # Weiße Index für Elternteil B zu: erstes Elternteil der Population\n",
    "            else:\n",
    "                parent_B = (parent_counter + 1) # Weise Index für Elternteil B zu\n",
    "            \n",
    "            \n",
    "            self.list_of_parent_pairs_for_crossover.append((parent_A, parent_B)) # Füger das erzeugte Elternpaar der Liste hinzu, welche alle Elternpaare enthält die miteinander rekombiniert werden sollen\n",
    "            parent_counter += 2 # Erhöhe Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "\n",
    "\n",
    "    # Funktion zur Erzeugungvon Elternpaaren (FWBH) für den Crossover: Bester mit besserer Häfte\n",
    "    def get_parent_pairs_first_with_better_half(self):\n",
    "\n",
    "        # Initialisiere Zählervariable für die Auswahl des Elternteils A bzw. B\n",
    "        parent_A = 0\n",
    "        parent_B = 0\n",
    "        # Initialisiere Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "        parent_counter = 0\n",
    "\n",
    "        while (parent_counter < self.number_of_parents/2): # Überprüfe, ob bereits alle Eltern berücksichtigt wurden\n",
    "            \n",
    "            parent_A = 0 # Weise Index für Elternteil A zu (Betse Lösung)\n",
    "            parent_B = parent_counter + 1     \n",
    "            \n",
    "            self.list_of_parent_pairs_for_crossover.append((parent_A, parent_B)) # Füger das erzeugte Elternpaar der Liste hinzu, welche alle Elternpaare enthält die miteinander rekombiniert werden sollen\n",
    "            parent_counter += 1 # Erhöhe Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "\n",
    "\n",
    "    # Funktion zur Erzeugungvon Elternpaaren (BHWF) für den Crossover: besere Hälfte mit Bestem\n",
    "    def get_parent_pairs_better_half_with_first(self):\n",
    "\n",
    "        # Initialisiere Zählervariable für die Auswahl des Elternteils A bzw. B\n",
    "        parent_A = 0\n",
    "        parent_B = 0\n",
    "        # Initialisiere Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "        parent_counter = 0\n",
    "\n",
    "        while (parent_counter < self.number_of_parents/2): # Überprüfe, ob bereits alle Eltern berücksichtigt wurden\n",
    "            \n",
    "            parent_A = parent_counter + 1 # Weise Index für Elternteil A zu \n",
    "            parent_B = 0 # Weise Index für Elternteil B zu (Betse Lösung)\n",
    "            \n",
    "            \n",
    "            self.list_of_parent_pairs_for_crossover.append((parent_A, parent_B)) # Füger das erzeugte Elternpaar der Liste hinzu, welche alle Elternpaare enthält die miteinander rekombiniert werden sollen\n",
    "            parent_counter += 1 # Erhöhe Zählervariable für die Auswahl des nächsten noch nicht berücksichtigten Elternteils\n",
    "    '''Ende der Funktionen für die Berechnung der Elternpaarzuweisung'''\n",
    "\n",
    "\n",
    "\n",
    "    '''Funktionen für die Verschiedenen Crossovervarianten'''\n",
    "    # Crossovervariante 0: Erzeuge 2 Nachkommen aus 2 Eltern\n",
    "    # 1. Nachkommen: Erste gepackte Containerhälfte beider Eltern zuerst\n",
    "    # 2. Nachkommen: Zweite gepackte Containerhälfte beider Eltern zuerst\n",
    "    def create_two_offsprings_by_first_second_package_half_first(self, parent_A, parent_B, pack_order_offspring_A, pack_order_offspring_B):\n",
    "        \n",
    "        # Erzeuge Nachkommen A\n",
    "\n",
    "        # wähle die als erstes gepackte Hälfte der Container in Elternteil A und dann B aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein \n",
    "        # (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige erste 4 Conatiner)\n",
    "        pack_order_offspring_A = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "        pack_order_offspring_A = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "\n",
    "        # wähle die zweite Hälfte der gepackten Container in Elternteil A und dann B aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein \n",
    "        # (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige ab Conatiner 5)\n",
    "        pack_order_offspring_A = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "        pack_order_offspring_A = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "\n",
    "        # Erzeuge Nachkommen B\n",
    "\n",
    "        # wähle die zweite Hälfte der gepackten Container in Elternteil A und dann B aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein \n",
    "        pack_order_offspring_B = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_B)\n",
    "        pack_order_offspring_B = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_B)\n",
    "\n",
    "        # wähle die als erstes gepackte Hälfte der Container in Elternteil A und dann B aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein \n",
    "        pack_order_offspring_B = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_B)\n",
    "        pack_order_offspring_B = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_B)\n",
    "\n",
    "        return pack_order_offspring_A, pack_order_offspring_B\n",
    "\n",
    "    # Crossovervariante 1: Erzeuge 2 Nachkommen aus 2 Eltern\n",
    "    # Gepackte Container deren Auslastung > der durchschnittlichen Auslastung der Lösung sind zuerst\n",
    "    def create_two_offsprings_by_package_half_with_highest_volume_usage_first(self, parent_A, parent_B, pack_order_offspring_A, pack_order_offspring_B):\n",
    "        \n",
    "        # Erzeuge Nachkommen A\n",
    "\n",
    "        # wähle die die Container in Elternteil A bzw. B aus, deren Auslastung über der durchschnittlichen Auslastung des Elternteils liegt aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein\n",
    "        pack_order_offspring_A = self.pick_containers_above_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "        pack_order_offspring_A = self.pick_containers_above_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "\n",
    "        # wähle die die Container in Elternteil A bzw. B aus, deren Auslastung unterhalb der durchschnittlichen Auslastung des Elternteils liegt aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein\n",
    "        pack_order_offspring_A = self.pick_containers_below_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "        pack_order_offspring_A = self.pick_containers_below_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "\n",
    "        # Erzeuge Nachkommen B\n",
    "\n",
    "        # wähle die die Container in Elternteil B bzw. A aus, deren Auslastung über der durchschnittlichen Auslastung des Elternteils liegt aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein\n",
    "        pack_order_offspring_B = self.pick_containers_above_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_B)\n",
    "        pack_order_offspring_B = self.pick_containers_above_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_B)\n",
    "\n",
    "        # wähle die die Container in Elternteil B bzw. A aus, deren Auslastung unterhalb der durchschnittlichen Auslastung des Elternteils liegt aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein\n",
    "        pack_order_offspring_B = self.pick_containers_below_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_B)\n",
    "        pack_order_offspring_B = self.pick_containers_below_average_volume_usage_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_B)\n",
    "\n",
    "        return pack_order_offspring_A, pack_order_offspring_B\n",
    "\n",
    "    # Crossovervariante 2: Erzeuge 2 Nachkommen aus 2 Eltern\n",
    "    # 1. Nachkommen: Erste gepackte Containerhälfte beider Elternteile zuerst\n",
    "    def create_two_offsprings_by_first_package_half_first(self, parent_A, parent_B, pack_order_offspring_A, pack_order_offspring_B):\n",
    "        \n",
    "        # Erzeuge Nachkommen A\n",
    "\n",
    "        # wähle die als erstes gepackte Hälfte der Container in Elternteil A und dann B aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein \n",
    "        # (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige erste 4 Conatiner)\n",
    "        pack_order_offspring_A = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "        pack_order_offspring_A = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "\n",
    "        # wähle die zweite Hälfte der gepackten Container in Elternteil A und dann B aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein \n",
    "        # (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige ab Conatiner 5)\n",
    "        pack_order_offspring_A = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "        pack_order_offspring_A = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "\n",
    "        # Erzeuge Nachkommen B\n",
    "\n",
    "        # wähle die als erstes gepackte Hälfte der Container in Elternteil B und dann A aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige erste 4 Conatiner)\n",
    "        pack_order_offspring_B = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "        pack_order_offspring_B = self.pick_first_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "\n",
    "        # wähle die zweite Hälfte der gepackten Container in Elternteil B und dann A aus und Füge deren Packreihenfolge in die Packreihenfolge des Nachkommens ein (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige ab Conatiner 5)\n",
    "        pack_order_offspring_B = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_B], pack_order_offspring_A)\n",
    "        pack_order_offspring_B = self.pick_second_half_of_parent_pack_order(self.parent_solutions[parent_A], pack_order_offspring_A)\n",
    "\n",
    "        return pack_order_offspring_A, pack_order_offspring_B\n",
    "    '''Ende Funktionen für die Verschiedenen Crossovervarianten'''\n",
    "\n",
    "\n",
    "    '''Sub-Funktionen für die Verschiedenen Crossovervarianten'''\n",
    "    '''Subfunktionen der Crossovervariante 0 & 2'''\n",
    "    # Crossovervariante 0 & 2: Zieht die Packreihenfolge von der als erstes gepackten Conatinerhälfte heran und fügt sie der Packreihenfolge des Nachkommen hinzu\n",
    "    def pick_first_half_of_parent_pack_order(self, parent, pack_order_offspring):\n",
    "        \n",
    "        # Initialisiere Anzahl Container des Elternteils\n",
    "        conatiners_in_parent = parent.container_number\n",
    "        # Initialisiere Zählervariable für die Auswahl eines spezifischen Containers des Elternteils (Starte mit erstem Container der ersten Hälfte)\n",
    "        picked_container_in_parent = 0\n",
    "        \n",
    "        # wähle die als erstes gepackte Hälfte der Container im Elternteil aus und Füge deren Packreihenfolge in die neu zu erzeugende Packreihenfolge ein (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige erste 4 Conatiner)\n",
    "        while (picked_container_in_parent < (conatiners_in_parent/2)): \n",
    "            # Durchlaufe alle Packstücke des gewählten Containers aus dem Elternteil\n",
    "            for article in parent.containers[picked_container_in_parent].article_locations:\n",
    "                if (article.package_ID not in pack_order_offspring): # Überprüfe ob der Artikel noch nicht in der Packreihenfolge dieses Nachkommen vorkommt\n",
    "                    pack_order_offspring.append(article.package_ID) # und füge die Packstück ID aller Packstücke dieses Containers der Reihe nach der Packstückreihenfolge des Nachkommen hinzu\n",
    "\n",
    "            picked_container_in_parent += 1 # Erhöhe Zählervariable für die Containerauswahl des Elternteils\n",
    "        \n",
    "        # Gebe die erzeugte (Teil-)Packreihenfolge des Nachkommens zurück\n",
    "        return pack_order_offspring\n",
    "\n",
    "    # Crossovervariante 0 & 2: Zieht die Packreihenfolge von der als letztes gepackten Conatinerhälfte heran und fügt sie der Packreihenfolge des Nachkommen hinzu\n",
    "    def pick_second_half_of_parent_pack_order(self, parent, pack_order_offspring):\n",
    "        \n",
    "        # Initialisiere Anzahl Container des Elternteils\n",
    "        conatiners_in_parent = parent.container_number\n",
    "        # Initialisiere Zählervariable für die Auswahl eines spezifischen Containers des Elternteils (Starte mit erstem Container der zweiten Hälfte)\n",
    "        picked_container_in_parent = round(conatiners_in_parent/2) # aufrunden für ungerade Containeranzahl in Elternteil (ist die gesamte Containerzahl ungerade wird aufgerundet z.B. Containeranzahl = 7, berücksichtige ab Conatiner 5)\n",
    "        \n",
    "        # wähle die zweite Hälfte der gepackten Container im Elternteil aus und Füge deren Packreihenfolge in die neu zu erzeugende Packreihenfolge ein \n",
    "        while (picked_container_in_parent < conatiners_in_parent): \n",
    "            # Durchlaufe alle Packstücke des gewählten Containers aus dem Elternteil\n",
    "            for article in parent.containers[picked_container_in_parent].article_locations:\n",
    "                if (article.package_ID not in pack_order_offspring): # Überprüfe ob der Artikel noch nicht in der Packreihenfolge dieses Nachkommen vorkommt\n",
    "                    pack_order_offspring.append(article.package_ID) # und füge die Packstück ID aller Packstücke dieses Containers der Reihe nach der Packstückreihenfolge des Nachkommen hinzu\n",
    "\n",
    "            picked_container_in_parent += 1 # Erhöhe Zählervariable für die Containerauswahl des Elternteils\n",
    "        \n",
    "        # Gebe die erzeugte (Teil-)Packreihenfolge des Nachkommens zurück\n",
    "        return pack_order_offspring\n",
    "    '''Ende der Subfunktionen der Crossovervariante 0 & 2'''\n",
    "\n",
    "    '''Subfunktionen der Crossovervariante 1'''\n",
    "    # Crossovariante 1: Zieht die Packreihenfolge der Conatiner heran, deren Auslastung höher als die durchschnittliche Auslastung des übergebenen Elterteils ist und fügt sie der Packreihenfolge des Nachkommen hinzu\n",
    "    def pick_containers_above_average_volume_usage_of_parent_pack_order(self, parent, pack_order_offspring):\n",
    "        \n",
    "        # Initialisiere Anzahl Container des Elternteils\n",
    "        conatiners_in_parent = parent.container_number\n",
    "        # Initialisiere die durchschnittliche Auslastung des Elternteils\n",
    "        average_usage_of_parent = parent.usage_average\n",
    "        # Initialisiere Liste die die (restlichen) Container des übergebenen Elternteils enthält\n",
    "        parent_containers = copy.deepcopy(parent)\n",
    "        \n",
    "        # Durchlaufe dafür alle Container so oft, wie es noch einen Container gibt, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde & dessen Auslastung höher ist als die durchschnittliche Auslastung des Elternteils\n",
    "        for nr_of_container_iterations in range(conatiners_in_parent):\n",
    "\n",
    "            # Initialisiere Variable zum Speichern der Auslastung des Containers mit der höchsten Auslastung, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde\n",
    "            volume_usage_of_best_container = 0\n",
    "            # Initialisiere Variable zum Speichern des Index des Containers mit der höchsten Auslastung, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde\n",
    "            index_of_best_container = -1\n",
    "            # Initialisiere Variable zum Speichern der Auslastung eines ausgewählten Containers\n",
    "            volume_usage_of_selected_container = 0\n",
    "            # Initialisiere die Anzhal an Conatainern des Elternteils, die noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurden\n",
    "            not_packed_conatiners_in_parent = len(parent_containers.containers)\n",
    "\n",
    "            # Durchlaufe alle Container, die noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurden und finde davon den Container mit der höchsten Auslastung\n",
    "            for container_index in range(not_packed_conatiners_in_parent):\n",
    "                volume_usage_of_selected_container = parent_containers.containers[container_index].volume_usage_rate # Speichere die Volumenauslastung des aktuell betrachteten Containers\n",
    "                if (volume_usage_of_selected_container > volume_usage_of_best_container): # Überprüfe, ob die Volumenasulastung des aktuell betrachteten Containers der bisher größten erfassten Auslastung entspricht\n",
    "                    volume_usage_of_best_container = volume_usage_of_selected_container # Speicher die Auslastung dieses Containers als die bisher größte erfasste Auslastung\n",
    "                    index_of_best_container = container_index # Speicher den Index dieses Containers\n",
    "                \n",
    "                # Erhöhe den Container Index um eins, um die Schleife für den Nächsten Container erneut zu starten\n",
    "                container_index += 1\n",
    "            \n",
    "            # Nachdem der Container mit der größten Auslastung identifirt ist, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde:\n",
    "            if (volume_usage_of_best_container >= average_usage_of_parent): # Überprüfe, ob dessen Auslastung höher ist als die durchschnittliche Auslastung des Elternteils\n",
    "                # Durchlaufe alle Packstücke des gewählten Containers aus dem Elternteil\n",
    "                for article in parent_containers.containers[index_of_best_container].article_locations:\n",
    "                    if (article.package_ID not in pack_order_offspring): # Überprüfe ob der Artikel noch nicht in der Packreihenfolge dieses Nachkommen vorkommt\n",
    "                        pack_order_offspring.append(article.package_ID) # und füge die Packstück ID aller Packstücke dieses Containers der Reihe nach der Packstückreihenfolge des Nachkommen hinzu\n",
    "\n",
    "                # Entferne den gewählten Container aus der Containermenge des Elternteils\n",
    "                del parent_containers.containers[index_of_best_container]\n",
    "            \n",
    "            else: # Bereits alle Container, deren Auslastung größer als die durchschnittlichen Volumenauslatung des Elternteils ist wurden der Packreihenfolge des Nachkommens hinzugefügt\n",
    "                break # Unterbreche die Suche nach weiteren Containern\n",
    "            \n",
    "            # Erhöhe die Anzahl der durchgeführten Durchsuchungen aller Conatiner nach einem Container, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde & dessen Auslastung höher ist als die durchschnittliche Auslastung des Elternteils\n",
    "            nr_of_container_iterations += 1\n",
    "        \n",
    "        # Gebe die erzeugte (Teil-)Packreihenfolge des Nachkommens zurück\n",
    "        return pack_order_offspring\n",
    "        \n",
    "    # Crossovervariante 1: Zieht die Packreihenfolge der Conatiner heran, deren Auslastung geringer als die durchschnittliche Auslastung des übergebenen Elterteils ist und fügt sie der Packreihenfolge des Nachkommen hinzu\n",
    "    def pick_containers_below_average_volume_usage_of_parent_pack_order(self, parent, pack_order_offspring):\n",
    "        \n",
    "        # Initialisiere Anzahl Container des Elternteils\n",
    "        conatiners_in_parent = parent.container_number\n",
    "        # Initialisiere die durchschnittliche Auslastung des Elternteils\n",
    "        average_usage_of_parent = parent.usage_average\n",
    "        # Initialisiere Liste die die (restlichen) Container des übergebenen Elternteils enthält\n",
    "        parent_containers = copy.deepcopy(parent)\n",
    "        \n",
    "        # Durchlaufe dafür alle Container so oft, wie es noch einen Container gibt, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde & dessen Auslastung höher ist als die durchschnittliche Auslastung des Elternteils\n",
    "        for nr_of_container_iterations in range(conatiners_in_parent):\n",
    "\n",
    "            # Initialisiere Variable zum Speichern der Auslastung des Containers mit der höchsten Auslastung unterhalb des Auslastungsdurchschnitts, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde\n",
    "            volume_usage_of_best_container_below_average = 0\n",
    "            # Initialisiere Variable zum Speichern des Index des Containers mit der höchsten Auslastung unterhalb des Auslastungsdurchschnitts, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde\n",
    "            index_of_best_container_below_average = -1\n",
    "            # Initialisiere Variable zum Speichern der Auslastung eines ausgewählten Containers\n",
    "            volume_usage_of_selected_container = 0\n",
    "            # Initialisiere die Anzhal an Conatainern des Elternteils, die noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurden\n",
    "            not_packed_conatiners_in_parent = len(parent_containers.containers)\n",
    "\n",
    "            # Durchlaufe alle Container, die noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurden und finde davon den Container mit der höchsten Auslastung unterhalb des Auslastungsdurchschnitts\n",
    "            for container_index in range(not_packed_conatiners_in_parent):\n",
    "                volume_usage_of_selected_container = parent_containers.containers[container_index].volume_usage_rate # Speichere die Volumenauslastung des aktuell betrachteten Containers\n",
    "                if (volume_usage_of_selected_container > volume_usage_of_best_container_below_average and volume_usage_of_selected_container < average_usage_of_parent): # Überprüfe, ob die Volumenasulastung des aktuell betrachteten Containers der bisher größten erfassten Auslastung unterhalb des Auslastungsdurchschnitts entspricht\n",
    "                    volume_usage_of_best_container_below_average = volume_usage_of_selected_container # Speicher die Auslastung dieses Containers als die bisher größte erfasste Auslastung unterhalb des Auslastungsdurchschnitts\n",
    "                    index_of_best_container_below_average = container_index # Speicher den Index dieses Containers\n",
    "                \n",
    "                # Erhöhe den Container Index um eins, um die Schleife für den Nächsten Container erneut zu starten\n",
    "                container_index += 1\n",
    "            \n",
    "            # Nachdem der Container mit der größten Auslastung unterhalb des Auslastungsdurchschnitts identifirt ist, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde:\n",
    "            if (volume_usage_of_best_container_below_average > 0): # Überprüfe, ob es überhaupt noch solch einen Conatiner gab\n",
    "                # Durchlaufe alle Packstücke des gewählten Containers aus dem Elternteil\n",
    "                for article in parent_containers.containers[index_of_best_container_below_average].article_locations:\n",
    "                    if (article.package_ID not in pack_order_offspring): # Überprüfe ob der Artikel noch nicht in der Packreihenfolge dieses Nachkommen vorkommt\n",
    "                        pack_order_offspring.append(article.package_ID) # und füge die Packstück ID aller Packstücke dieses Containers der Reihe nach der Packstückreihenfolge des Nachkommen hinzu\n",
    "\n",
    "                # Entferne den gewählten Container aus der Containermenge des Elternteils\n",
    "                del parent_containers.containers[index_of_best_container_below_average]\n",
    "            \n",
    "            else: # Bereits alle Container, deren Auslastung kleiner als die durchschnittlichen Volumenauslatung des Elternteils ist wurden der Packreihenfolge des Nachkommens hinzugefügt\n",
    "                break # Unterbreche die Suche nach weiteren Containern\n",
    "            \n",
    "            # Erhöhe die Anzahl der durchgeführten Durchsuchungen aller Conatiner nach einem Container, der noch nicht der Packreihenfolge des Nachkommens hinzugefügt wurde & dessen Auslastung geringer ist als die durchschnittliche Auslastung des Elternteils\n",
    "            nr_of_container_iterations += 1\n",
    "        \n",
    "        # Gebe die erzeugte (Teil-)Packreihenfolge des Nachkommens zurück\n",
    "        return pack_order_offspring\n",
    "    '''Ende der Subfunktionen der Crossovervariante 1'''\n",
    "    '''Ende der Sub-Funktionen für die Verschiedenen Crossovervarianten'''\n",
    "\n",
    "\n",
    "\n",
    "    '''Funktionen für die Mutation'''\n",
    "    # Bekommt die Packreihenfolge aller Nachkommen übergeben und mutierte diese solange bis eine noch nicht vorgekommene Packreihenfolge entsteht\n",
    "    def mutation(self, tabu_list):\n",
    "        for offspring_index in range(len(self.pack_orders)): # Durchlaufe die Packreihenfolge aller Nachkommen\n",
    "\n",
    "            self.pack_orders[offspring_index] = self.change_2_random_articles(self.pack_orders[offspring_index]) # Führe Funktion für Mutation auf: tauschen 2er zufällig gewählter Artikel aus\n",
    "            \n",
    "            if (self.check_if_pack_order_already_used(self.pack_orders[offspring_index], tabu_list) == True): # Mutiere so lange weiter, bis ein noch nicht verwendete Packreihenfolge entsteht \n",
    "                \n",
    "                self.pack_orders[offspring_index] = self.change_2_random_articles(self.pack_orders[offspring_index])\n",
    "    # Tausche zwei zufällig gewählte Artikel in der übergebenen Packreihenfolge\n",
    "    def change_2_random_articles(self, pack_order):\n",
    "        # Initialisiere Variable zum Zwischenspeichern der Artikel ID, des zu tauschenden Artikels\n",
    "        article_ID_of_article_1 = 0\n",
    "\n",
    "        # Initialisiere Index Variable für die beiden zu tauschenden Artikel. Wähle dabei den Index zwischen 0 und der Anzahl an Artikeln in dieser Packreihenfolge\n",
    "        index_articel_1 = random.randrange(0,len(pack_order))\n",
    "        index_articel_2 = random.randrange(0,len(pack_order))\n",
    "        article_ID_of_article_1 = pack_order[index_articel_1] # Speichere die Artikel ID des ersten Artikels zwischen\n",
    "        pack_order[index_articel_1] = pack_order[index_articel_2] # Überschreibe die Position des ersten Artikels mit der Artikel ID des zweiten Artikels\n",
    "        pack_order[index_articel_2] = article_ID_of_article_1 # Überschreibe die Position des zweiten Artikels mit der Artikel ID des ersten Artikels\n",
    "    \n",
    "        return pack_order\n",
    "\n",
    "    # Funktion die überprüft, ob die übergebene PAckreihenfolge bereits verwendet wurden. Durch Abgleich mit der Tabu-Liste\n",
    "    def check_if_pack_order_already_used(self, pack_order, tabu_list):\n",
    "        pack_order_already_used = pack_order in tabu_list # Überprüfe, ob die übergeben Packreihenfolge bereits berechnet wurde, falls ja: True\n",
    "        return pack_order_already_used\n",
    "    '''Ende der Funktionen für die Mutation'''\n",
    "\n",
    "\n",
    "\n",
    "    '''Funktionen für die Erzeugung von Packreihenfolgen'''\n",
    "    # Erzeuge die Packreihenfolgen für die Startpopulation\n",
    "    def create_start_population_pack_orders(self, article_count):   \n",
    "        # Erzeuge eine Liste, welche die Artikel ID jedes Packstücks enthält, wie sie in den MPS enthalten ist. Also beginnend mit 1\n",
    "        all_article_IDs = [article_ID for article_ID in range(1, (article_count + 1))]\n",
    "\n",
    "        self.add_pack_order(all_article_IDs) # Füge die Packreihenfolge des initialen MPS Datensatzes hinzu\n",
    "        \n",
    "        for i in range(self.population_size):\n",
    "            random.seed(article_count+i) # Setze einen Seed für die Reproduzierbarkeit der erzeugten Reihenfolge, Seed muss sich pro Durchgang ädnern, damit unterschiedliche Reihenfolgen erzeugt werden\n",
    "            self.add_pack_order(random.sample(all_article_IDs, len(all_article_IDs))) # Füge erzeugte gemischte Packreihenfolge der Liste für alle Reihenfolgen hinzu\n",
    "    \n",
    "    # Funktion zum Erzeugen der Packreihenfolge einer Nachkommen-Population\n",
    "    def create_packing_orders_for_current_offspring_generation(self, tabu_list, list_of_choosen_crossovers):\n",
    "        '''Starte Selektion'''\n",
    "\n",
    "        # Selektiere Eltern die für die Rekombination berücksichtigt werden sollen\n",
    "        self.ceep_parents_for_pairing()\n",
    "\n",
    "        '''Ende Selektion'''\n",
    "\n",
    "\n",
    "        '''Starte Crossover'''\n",
    "\n",
    "        # Bilde die Elternpaare für den Crossover anhand des ausgewählten Verfahrens\n",
    "        self.create_parent_pairs()\n",
    "\n",
    "        # Initialisiere Index zum iterieren der Liste für die durchzuführenden Crossovervarianten\n",
    "        list_index = 0\n",
    "\n",
    "        # Führe einen Crossover für jedes Elternpaar für jede festgelegte Crossovervariante durch:\n",
    "        while(list_index < len(list_of_choosen_crossovers)): # Jedes Elternpaar wird mit in der Liste definierten Crossover Varianten rekombiniert\n",
    "            \n",
    "            nr_of_crossover_variant = list_of_choosen_crossovers[list_index] # Weise Crossovervariante zu, welche diese Schleifeniteration durchgeführt werden soll\n",
    "\n",
    "            # Führe für jedes Elternpaar die definierte Corssovervariante durch\n",
    "            for parent_pair in self.list_of_parent_pairs_for_crossover:\n",
    "                parent_A = parent_pair[0] # Weise den Index für Elternteil A zu\n",
    "                parent_B = parent_pair[1] # Weise den Index für Elternteil B zu\n",
    "\n",
    "                # Initialisiere Listen, in welche die Packreihenfolgen der beiden Nachkommen gespeichert werden\n",
    "                pack_order_offspring_A = []\n",
    "                pack_order_offspring_B = []\n",
    "\n",
    "                if (nr_of_crossover_variant == 0): # 0. Crossovervariante\n",
    "\n",
    "                    pack_order_offspring_A, pack_order_offspring_B = self.create_two_offsprings_by_first_second_package_half_first(parent_A, parent_B, pack_order_offspring_A, pack_order_offspring_B)\n",
    "\n",
    "                elif (nr_of_crossover_variant == 1): # 1. Crossovervariante\n",
    "                    \n",
    "                    pack_order_offspring_A, pack_order_offspring_B = self.create_two_offsprings_by_package_half_with_highest_volume_usage_first(parent_A, parent_B, pack_order_offspring_A, pack_order_offspring_B)\n",
    "\n",
    "                elif (nr_of_crossover_variant == 2): # 2. Crossovervariante\n",
    "\n",
    "                    pack_order_offspring_A, pack_order_offspring_B = self.create_two_offsprings_by_first_package_half_first(parent_A, parent_B, pack_order_offspring_A, pack_order_offspring_B)\n",
    "\n",
    "                else: # In der Liste für die durchzuführenden Crossovervarianten wurde eine Zahl aufgenommen, für die keine Crossovervariante definiert ist\n",
    "                    print(\"!!!!!!! Die Liste für Crossovervarianten enthält einen nicht definierten Wert. !!!!!!!\")\n",
    "                    break\n",
    "                self.add_pack_order(pack_order_offspring_A) # Füge die neue erzeugte Packreihenfolge des Nachkommens A der Liste aller Nachkommen hinzu\n",
    "                self.add_pack_order(pack_order_offspring_B) # Füge die neue erzeugte Packreihenfolge des Nachkommens B der Liste aller Nachkommen hinzu\n",
    "\n",
    "            list_index += 1 # Erhöhe Index zum iterieren der Liste für die durchzuführenden Crossovervarianten\n",
    "\n",
    "        '''Ende Crossover'''\n",
    "\n",
    "\n",
    "        '''Start Mutation'''\n",
    "\n",
    "        self.mutation(tabu_list) # Mutiere alle Packreihenfolgen und weiße sie der Populationsinstanz zu\n",
    "           \n",
    "        '''Ende Mutation'''\n",
    "    '''Ende Funktionen für die Erzeugung von Packreihenfolgen'''\n",
    "\n",
    "\n",
    "\n",
    "    '''Funktionen für die Erzeugung von MPS Datensätzen'''\n",
    "    # Erzeuge die MPS Datensätze für alle Packreihenfolgen der Startpopulation\n",
    "    def create_start_population_mps(self, initial_modified_order_data):\n",
    "        for pack_order in self.pack_orders: # Durchlaufe alle erzeugten Packreihenfolgen der ersten Population\n",
    "            # Rufe Funktion auf, um MPS für die entsprechende Packreihenfolge zu erzeugen, übergebe initialen MPS Datensatz, Packreihenfolge des Individuums\n",
    "            self.create_MPS_for_individual(initial_modified_order_data, pack_order)\n",
    "       \n",
    "    # Erzeuge die MPS Datensätze für alle Packreihenfolgen einer Nachkommen-Population\n",
    "    def create_offspring_population_mps(self, initial_modified_order_data):\n",
    "        for pack_order in self.pack_orders: # Durchlaufe alle Packreihenfolgen der Population\n",
    "            # Rufe Funktion auf, um MPS für die entsprechende Packreihenfolge zu erzeugen, übergebe initialen MPS Datensatz, Packreihenfolge des Individuums\n",
    "            self.create_MPS_for_individual(initial_modified_order_data, pack_order)\n",
    "\n",
    "    # Erzeuge den MPS Datensatz für eine übergebene Packreihenfolge (Genotyp)\n",
    "    def create_MPS_for_individual(self, initial_modified_order_data, pack_order_offspring):\n",
    "        # Initialisiere eine leere Liste um den MPS Datensatz eines Nachkommens darin zu speichern\n",
    "        mps_for_offspring = []\n",
    "        for package_index in range(len(pack_order_offspring)): # Durchlaufe die Packstückreihenfolge des Nachkommen\n",
    "            package_ID = pack_order_offspring[package_index] # Speichere die Packstück ID für das aktuell betrachtete Packstück in der Reihenfolge\n",
    "            mapping_package_ID_to_list_index = package_ID -1 # Ziehe von der Packstück ID eins um den korrekten Listenindex zu haben\n",
    "            mps_for_offspring.append(initial_modified_order_data[mapping_package_ID_to_list_index][:]) # Wähle durch den korrekten Listenindex die MPS Daten für das betrachtete Packstück aus dem initialen MPS Datensatz aus und Füge es der Liste für den MPS Datensatz des Nachkommens hinzu\n",
    "        \n",
    "        self.add_mps_dataset(mps_for_offspring)\n",
    "        # return mps_for_offspring # Gebe den erzeugten MPS Datensatz für den Nachkommen zurück\n",
    "    '''Ende Funktionen für die Erzeugung von MPS Datensätzen'''\n",
    "    \n",
    "\n",
    "\n",
    "    '''Funktionen für die Berechnung der Fitness'''\n",
    "    # Liefere die Lösung für jede Populationsinstanz sortiert nach durchschnittlicher Containerauslastung (größte Auslatsung zuerst)\n",
    "    def get_population_solutions(self, container_data, index_best_solution):\n",
    "        # Initialisiere Liste, um die Volumenauslastung jeder Lösung zu speichern\n",
    "        volume_usage_each_solution = []\n",
    "\n",
    "        for modified_order_data in self.mps_datasets:\n",
    "            solution = Solution(modified_order_data, container_data) # erzeugte einer leere Lösung und Initailisiere sie mit der MPS Packreihenfolge & den Containerdaten\n",
    "            solution.calculate_solution() # Berechne die Lösung\n",
    "            volume_usage_each_solution.append(solution.usage_average) # Speichere die Volumenauslastung in der Liste mit den Ausalstungen aller Lösungen\n",
    "            \n",
    "            self.add_population_solution(solution) # Speichere die Lösung mit ihrer Volumenauslastung in einer Liste\n",
    "\n",
    "        # Berechen den Index der Lösung mit der höchsten Auslastung\n",
    "        max_value = max(volume_usage_each_solution)\n",
    "        max_index = volume_usage_each_solution.index(max_value)\n",
    "\n",
    "        index_best_solution.append(max_index) # Füge den Index der Liste mit den Indizes der besten Lösung jeder Population hinzu  \n",
    "        return index_best_solution\n",
    "    '''Ende Funktionen für die Berechnung der Fitness'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "class Genetic_Algorithm:\n",
    "    def __init__(self, initial_modified_order_data, container_data, population_size, nr_of_iterations, choosen_parent_pairing, list_of_choosen_crossovers, nr_of_parents_to_keep):\n",
    "        self.initial_modified_order_data = initial_modified_order_data\n",
    "        self.container_data = container_data\n",
    "\n",
    "        self.population_size = population_size # Initialisiere die Populationsgröße\n",
    "        self.number_of_parents = population_size # Initialisiere die Anzahl an berücksichtigten Eltern\n",
    "        self.nr_of_iterations = nr_of_iterations # Initialisiere die Anzahl der Iterationen\n",
    "        self.choosen_parent_pairing = choosen_parent_pairing # Initialisiere Variable zur Festlegung der Paarbildungsvariante\n",
    "        self.list_of_choosen_crossovers = list_of_choosen_crossovers # Initialisiere Liste zur Festlegung der Crossovervariante\n",
    "        self.nr_of_parents_to_keep = nr_of_parents_to_keep # Initialisiere Variable zur Festlegung der Anzahl an Eltern, die bei der Populationsbildung aus der Vorgängerpopulation mitberücksichtigt werden sollen\n",
    "\n",
    "        self.iteration_numbers = [] # Initialisiere eine Liste, welche die Iterationsnummer nacheinander speichert (dient ausschließlich der Visualisierung)\n",
    "        self.best_volume_usage_values = [] # Initialisiere eine Liste, welche die Volumenauslastung der besten Lösung jeder Generation speichert (dient ausschließlich der Visualisierung)\n",
    "        self.index_best_solution = list() # Initialisiere eine Liste, welche den Index des besten Individuums einer Population trägt (dient ausschließlich der Visualisierung)\n",
    "\n",
    "        self.tabu_list = [] # Initialisiere eine Liste in der alle bereits verwendeten Packreihenfolgen gespeichert werden\n",
    "        \n",
    "    def add_iteration_number(self, iteration_number):\n",
    "        self.iteration_numbers.append(iteration_number)\n",
    "\n",
    "    def add_best_volume_usage(self, best_volume_usage):\n",
    "        self.best_volume_usage_values.append(best_volume_usage)\n",
    "\n",
    "    # Fügt eine übergebene Mange an Packreihenfolgen der Tabu-Liste hinzu fügt\n",
    "    def add_pack_orders_to_tabu_list(self, pack_orders_current_population):\n",
    "        for pack_order in pack_orders_current_population: # Durchlaufe die übergebenen Packreihenfolge\n",
    "            self.tabu_list.append(copy.deepcopy(pack_order)) # Füge jede Packreihenfolge der Tabu Liste hinzu\n",
    "\n",
    "\n",
    "    # Erzeugen & berechnen der ersten Population\n",
    "    def run_initial_population(self):\n",
    "            # Erzeuge eine leere Population\n",
    "            initial_population = Population(self.number_of_parents, self.population_size-1, [], self.choosen_parent_pairing) # -1 bei Populationsgröße weil das durch die Basisheuristik erzeugte Individuum in die Startpopulation ebenfalls miteinfließt (wird später hinzugefügt)\n",
    "            # Initialisiere die Anzahl der Packstücke\n",
    "            article_count = len(self.initial_modified_order_data)\n",
    "\n",
    "            # Erzuege die Packreihenfolgen für die erste Population\n",
    "            initial_population.create_start_population_pack_orders(article_count) \n",
    "            \n",
    "            # Füge die Packreihenfolgen der Liste mit allen bereits verwendeten Packreihenfolgen hinzu\n",
    "            self.add_pack_orders_to_tabu_list(initial_population.pack_orders)\n",
    "\n",
    "            # Erzeuge die MPS Datensätze für die erste Population\n",
    "            initial_population.create_start_population_mps(self.initial_modified_order_data)\n",
    "\n",
    "\n",
    "            # Berechne die Lösungen für jede MPS der ersten Population und sortiere sie nach Volumenauslastung (größte Auslastung am Anfang der Liste)\n",
    "            # Füge den IIndex der besten erzeugten Lösung in die entsprechende Visualisierungsliste ein\n",
    "            self.index_best_solution = initial_population.get_population_solutions(self.container_data, self.index_best_solution) \n",
    "     \n",
    "            # Sortiere die Lösungen nach Volumenauslastung (größte Auslastung am Anfang der Liste)\n",
    "            initial_population.sort_population_solutions()\n",
    "\n",
    "            # Füge die Iteratiosnnummer und die beste Auslastung der ersten Generation in die entsprechenden Visualisierungslisten ein\n",
    "            self.add_iteration_number(-self.nr_of_iterations)\n",
    "            self.add_best_volume_usage(initial_population.population_solutions[0].usage_average)\n",
    "            return initial_population\n",
    "\n",
    "\n",
    "    # Erzeugen & berechnen aller Folgegenerationen\n",
    "    def run_all_offspring_generations(self, initial_population):\n",
    "        # Initialisiere die Vorgängerpopulation mit der initialen Population\n",
    "        previous_population = initial_population\n",
    "\n",
    "        '''Durchlaufe die definierte Anzahl an Generationen'''\n",
    "\n",
    "        while (self.nr_of_iterations > 0):\n",
    "            # Erzeuge eine leere Population\n",
    "            current_population = Population(self.number_of_parents, self.population_size, previous_population.population_solutions, self.choosen_parent_pairing)\n",
    "            '''Code für die Durchführung des GAs nur mit Mutation'''\n",
    "            # # Weiße Packreihenfolge der vorherigen Generation der Packreihenfolge der aktuellen Generation zu\n",
    "            # current_population.pack_orders = previous_population.pack_orders\n",
    "            # # Führe nur Mutation durch\n",
    "            # current_population.mutation(self.tabu_list) # Mutiere alle Packreihenfolgen und weiße sie der Populationsinstanz zu\n",
    "            '''Ende des Codes für die Durchführung des GAs nur mit Mutation'''\n",
    "            \n",
    "            '''Abschnitt auskommentieren für nur Mutation'''\n",
    "            # Zusätzlich muss der Funktionsaufruf für die Mutation innerhalb der Funktion create_packing_orders_for_current_offspring_generation in der Klasse Population auskommentiert werden\n",
    "            # Erzeuge Packreihenfolgen für die neue Population\n",
    "            current_population.create_packing_orders_for_current_offspring_generation(self.tabu_list, self.list_of_choosen_crossovers) # Erzuege die Packreihenfolgen für die neue Generation\n",
    "            '''Ende des auskommentieren Abschnitts für nur Mutation'''\n",
    "\n",
    "            '''Lokale Suche für die beste Lösung (Abschnitt auskommentieren für Berechnungen ohne lokale Suche)'''\n",
    "            # Erzeuge Population nur mit bester Lösung der Vorgängerpopulation und mutiere sie für eine lokale Suche\n",
    "            dummy_population = copy.deepcopy(previous_population) # Erzeuge Kopie der Vorgängerpopulation\n",
    "            dummy_population.pack_orders = [dummy_population.pack_orders[0]] # Entferne alle Packreihenfolgen der Vorgängergeneration bis auf die beste\n",
    "            dummy_population.mutation(self.tabu_list) # Mutiere die beste Packreohenfolge der Vorgängergeneration\n",
    "            current_population.add_pack_order(dummy_population.pack_orders[0]) #Füge die mutierte Packreohenfolge den Packreihenfolgen der aktuellen Generation hinzu\n",
    "            '''Ende der lokalen Suche für die beste Lösung'''\n",
    "\n",
    "            # Füge die Packreihenfolgen der Liste mit allen bereits verwendeten Packreihenfolgen hinzu\n",
    "            self.add_pack_orders_to_tabu_list(current_population.pack_orders)\n",
    "            \n",
    "            # Erzeuge die MPS Datensätze für die aktuelle Population\n",
    "            current_population.create_offspring_population_mps(self.initial_modified_order_data)\n",
    "            \n",
    "            # Berechne die Lösung für jeden Nachkommen der aktuellen Population und sortiere die Lösungen nach der durchschnittlichen Volumenauslastung (größte Auslastung am Anfang der Liste)\n",
    "            # Füge den Index der besten erzeugten Lösung in die entsprechende Visualisierungsliste ein\n",
    "            self.index_best_solution = current_population.get_population_solutions(self.container_data, self.index_best_solution)\n",
    "            \n",
    "            '''Fortsetzung Lokale Suche für die beste Lösung (Abschnitt auskommentieren für Berechnungen ohne lokale Suche)'''\n",
    "            # Prüfe ob der durch die lokale Suche erzeugte Mutant schlechter ist als die nicht mutierte beste Lösung der Vorgängergeneration.\n",
    "            if current_population.population_solutions[-1].usage_average <= previous_population.population_solutions[0].usage_average: \n",
    "                current_population.population_solutions[-1] = previous_population.population_solutions[0] # Ersetze den Mutanten durch die beste Lösung der Vorgängergeneration\n",
    "                current_population.pack_orders[-1] = previous_population.pack_orders[0] # Ersetze die Packreihenfolge des Mutanten durch die der besten Lösung der Vorgängergeneration\n",
    "            '''Ende Fortsetzung der lokalen Suche für die beste Lösung'''\n",
    "            \n",
    "            '''Ohne lokale Suche (Abschnitt muss ausgeführt werden)'''\n",
    "            # # Ergänze beste x Lösung der Eltern in der Liste\n",
    "            # for parent_solution in itertools.islice(previous_population.population_solutions, 0, self.nr_of_parents_to_keep):\n",
    "            #     current_population.add_population_solution(parent_solution)\n",
    "            '''Ende ohne lokale Suche'''\n",
    "\n",
    "            # Sortiere die Lösungen nach Volumenauslastung (größte Auslastung am Anfang der Liste)\n",
    "            current_population.sort_population_solutions()\n",
    "            self.nr_of_iterations -= 1 # Verringere die Zählervariable für die Anzahl an Generationen/ Iterationen, die der genetischen Algorithmus noch durchlaufen soll\n",
    "            \n",
    "            # Speichere die erzeugte Population als Vorgängerpopulation für die nächste zu erzeugende Population\n",
    "            previous_population = current_population\n",
    "\n",
    "            # Füge die Iteratiosnnummer und die beste Auslastung der ersten Generation in die entsprechenden Visualisierungslisten ein\n",
    "            self.add_iteration_number(-self.nr_of_iterations)\n",
    "            self.add_best_volume_usage(current_population.population_solutions[0].usage_average)\n",
    "\n",
    "        '''Die definierte Anzahl an Generationen wurde durchlaufen'''\n",
    "        return current_population.population_solutions[0]\n",
    "\n",
    "\n",
    "    # Funktion die die Volumenauslastung über die Generationen & die beste erzeugte Lösung pro Population visualisiert\n",
    "    def show_line_chart_with_best_solutions_of_each_generation(self):\n",
    "        # Initialisiere die subplot Funktion\n",
    "        figure, axis = plt.subplots(2, 1, figsize=(25,10))\n",
    "\n",
    "        axis[0].plot(self.iteration_numbers, self.best_volume_usage_values)\n",
    "        axis[0].set_title('Population size: ' + str(self.population_size) + ', Iterations: ' + str(self.nr_of_iterations) + ', Crossover: ' + str(self.list_of_choosen_crossovers).strip('[]') + ', Pairing Variant: ' + str(self.choosen_parent_pairing))\n",
    "        axis[0].set_ylabel('Auslastung')\n",
    "\n",
    "        axis[1].plot(self.iteration_numbers, self.index_best_solution)\n",
    "        axis[1].set_xlabel('Populationsnummer')\n",
    "        axis[1].set_ylabel('Index beste neue Lösung')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    # Führe alle Iterationen des evolutionären Algorithmus durch\n",
    "    def run_genetic_algorithm(self):     \n",
    "        # Erzeuge und berechne die erste Population\n",
    "        initial_population = self.run_initial_population()\n",
    "\n",
    "        # Erzeuge und berechne die Populationen aller Folgegenerationen\n",
    "        best_solution = self.run_all_offspring_generations(initial_population)\n",
    "\n",
    "\n",
    "        # Erezuge einen line plot, der die Auslastung pro Generation anzeigt\n",
    "        # self.show_line_chart_with_best_solutions_of_each_generation()\n",
    "\n",
    "        # Gebe die finale Lösung zurück\n",
    "        return best_solution, self.best_volume_usage_values, self.index_best_solution\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Packing Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Packing_Algorithm:\n",
    "\n",
    "    def __init__(self, order_instance, population_size, nr_of_iterations, choosen_parent_pairing, list_of_choosen_crossovers, nr_of_parents_to_keep):\n",
    "        self.start_time = time.time() # Anfangszeit\n",
    "        self.end_time = 0 # Schlusszeit\n",
    "        self.time_needed = 0 # benötigte Zeit\n",
    "\n",
    "        # Dateinamen der Bestellung und der Containerliste festlegen\n",
    "        self.order_file_name = order_instance + \".xlsx\"\n",
    "        self.container_file_name = \"Containerliste\" + \".xlsx\"    \n",
    "\n",
    "        # Initialisiere Parameter für den Evolutionären Algorithmus\n",
    "        self.population_size = population_size # Startpopulationsgröße\n",
    "        self.nr_of_iterations = nr_of_iterations # Anzahl an Folgegenerationen die der evolutionöre Algorithmus erzeugen soll\n",
    "        self.choosen_parent_pairing = choosen_parent_pairing # Gewählte Elternselektion\n",
    "        self.list_of_choosen_crossovers = list_of_choosen_crossovers # Gewähltes Rekombinationsverfahren\n",
    "        self.nr_of_parents_to_keep = nr_of_parents_to_keep # Anzahl der besten Individuen, die in die Folgegeneration übernommen werden sollen. Hat nur Auswirkungen, wenn die lokale Suche in der Funktion run_all_offspring_generations der Klasse Populations nicht durchgeführt wird.\n",
    "        \n",
    "        # Rufe Datenvorverarbeitung auf und erhalte die initialen modifizierten Bestelldaten sortiert nach Packstückvolumen und Grundfläche der Orientierungen sowie die Containerdaten\n",
    "        self.initial_modified_order_data, self.container_data = data_preparation(self.order_file_name, self.container_file_name)\n",
    "\n",
    "        # Initialisiere die durch die Basisheuristik mit der initialen Packreihenfolge berechnete Lösung\n",
    "        self.best_solution_base = Solution(copy.deepcopy(self.initial_modified_order_data), self.container_data) # erzeugte einer leere Lösung und Initailisiere sie mit der initialen MPS Packreihenfolge & den Containerdaten\n",
    "        self.best_solution_base.calculate_solution() # Berechne die Lösung\n",
    "        \n",
    "\n",
    "        \n",
    "        # Initialisiere Variable zum speichern der durch die Verbesserungsheuristik erzeugten besten Lösung\n",
    "        self.best_solution_improve = 0\n",
    "\n",
    "        # Initialisiere Listen zum speichern der Simulationsdaten durch die Grid_Search\n",
    "        self.best_volume_usage_values = [] # Initialisiere eine Liste, welche die Volumenauslastung der besten Lösung jeder Generation speichert\n",
    "        self.index_best_solution = [] # Initialisiere eine Liste, welche den Index des besten Individuums einer Population trägt\n",
    "\n",
    "    \n",
    "    # Berechne die benötigte Zeit\n",
    "    def set_needed_time(self):\n",
    "        self.end_time = time.time() # Schlusszeit\n",
    "        self.time_needed = self.end_time - self.start_time # Berechne die benötigte Zeit\n",
    "\n",
    "\n",
    "    # Funktion, die Eigenschaften über die übergebene Lösung ausgibt\n",
    "    def print_solution_propertiers(self, best_solution):\n",
    "        print(\"Die gesamten Versandkosten liegen bei \" +  str(best_solution.costs) + \" €\")\n",
    "        print(\"Die durchschnittliche Containerauslastung liegt bei \" + str(best_solution.usage_average) + \" %\")\n",
    "        print(\"Es wurden \" + str(best_solution.container_number) + \" Container benötigt\")\n",
    "\n",
    "\n",
    "    # Funktion, die den gesamten Algorithmus ausführt\n",
    "    def run_algorithm(self):\n",
    "            \n",
    "        # Gebe die Ergebnisse der initialen Lösung aus\n",
    "        print(\"Ergebnis der Basisheuristik mit der sortierten Packreihenfolge nach Volumen und größter Grundfläche\")\n",
    "        self.print_solution_propertiers(self.best_solution_base)\n",
    "\n",
    "        # Visualisere gepackte Container der Lösung der Basisheuristik\n",
    "        # self.best_solution_base.visualize()\n",
    "        # Gebe Packplan der Lösung der Basisheuristik aus\n",
    "        print(\"Packplan Basisheuristik\")\n",
    "        print(self.best_solution_base.containers)\n",
    "\n",
    "        # Erzeuge eine Instanz des genetischen Algorithmus\n",
    "        genetic_algorithm = Genetic_Algorithm(self.initial_modified_order_data, self.container_data, self.population_size, self.nr_of_iterations, self.choosen_parent_pairing, self.list_of_choosen_crossovers, self.nr_of_parents_to_keep)\n",
    "        # Führe den genetischen Algorithmus aus\n",
    "        self.best_solution_improve, self.best_volume_usage_values, self.index_best_solution = genetic_algorithm.run_genetic_algorithm()\n",
    "\n",
    "        # Berechne die benötigte Zeit & gebe sie aus\n",
    "        self.set_needed_time()\n",
    "        print(\"Die Rechenzeit liegt bei \" + str(round(self.time_needed, 2)) + \" Sekunden\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        # Gebe die Ergebnisse der finalen Lösung mit der niedrigesten Volumenauslastung aus\n",
    "        print(\"Ergebnisse der finalen Lösung:\")\n",
    "        self.print_solution_propertiers(self.best_solution_improve)\n",
    "\n",
    "        print(\"\\n Relative Verbesserung zum Ergebnis der Basisheuristik:\")\n",
    "        print(str((self.best_solution_improve.usage_average/self.best_solution_base.usage_average - 1) * 100) + \"%\\n\")\n",
    "        \n",
    "        # Visualisere gepackte Container der besten Lösung\n",
    "        self.best_solution_improve.print_packplan()\n",
    "        self.best_solution_improve.visualize()\n",
    "        # Gebe Packplan der besten Lösung aus\n",
    "        print(\"Packplan der besten Lösung\")\n",
    "        print(self.best_solution_improve.containers)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        return self.best_volume_usage_values, self.index_best_solution, self.time_needed, self.best_solution_improve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import multiprocessing as mp\n",
    "\n",
    "# Klasse, in der verschiedene Ausprägungen der Parameter für den evolutionären Algorithmus definiert werden können. \n",
    "class Grid_Search:\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Definiere die zu simulierenden Benchmarkinstanzen\n",
    "        self.list_of_order_instances = [\"01_Datensatz_Beispiel_4\"]\n",
    "        # Definiere die Anzahl der Iteration\n",
    "        self.grid_nr_of_iterations = 10\n",
    "        # Definiere die Populationsgrößen\n",
    "        self.list_of_population_sizes = [10]\n",
    "        # Initialisiere Variable zur Auswahl der Verfahrens für die Bildung von Elternpaaren für den Crossover (0-5)\n",
    "        self.list_of_choosen_parent_pairing = [0]\n",
    "        # Initialisiere Liste zu Auswahl der durchzuführenden Crossovervarianten & befülle sie mit den folgenden Zahlen, um festzulegen mit welchen Crossovervarianten Nachkommen erzeugt werden sollen\n",
    "        # 0 = erste bzw. zweite Hälfte der Packreihenfolge beider Elternteile zuerst\n",
    "        # 1 = Container mit Auslastung > dem Auslastungsdurchschnitt zuerst\n",
    "        # 2 = erste Hälfte der Packreihenfolge zuerst. Von A bzw. B zuerst\n",
    "        self.list_of_lists_of_choosen_crossovers = [[1]]\n",
    "        \n",
    "        # Initialisiere Listen in welche die Ergebnisse aller Simulationen gespeichert werden\n",
    "        self.list_volume_usage_values = []\n",
    "        self. list_index_best_solution = []\n",
    "        self.list_packplan = []\n",
    "\n",
    "        # Initialisiere die aktuelle Zeit für den Dateinamen\n",
    "        self.timestamp = datetime.now().strftime(\"%Y-%m-%d %Hh%Mm%Ss\")\n",
    "\n",
    "    # Ruft den gesamten Algorithmus für jede in der Gittersuche definierte Parameterkombination auf.\n",
    "    def run_grid_search(self):\n",
    "\n",
    "        # Führe Simulationen für die verschiedenen Parameterausprägungen durch\n",
    "        for grid_order_instance in self.list_of_order_instances:\n",
    "            for grid_population_size in self.list_of_population_sizes:\n",
    "                for grid_list_of_choosen_crossovers in self.list_of_lists_of_choosen_crossovers:\n",
    "                    for grid_choosen_parent_pairing in self.list_of_choosen_parent_pairing:\n",
    "                        \n",
    "                        # Definiere die Anzahl an Eltern, die für die Bildung der neuen Population berücksichtigt werden sollen\n",
    "                        nr_of_parents_to_keep = 1 # Berücksichtige die beste Lösung der Vorgängerpopulation\n",
    "                        # nr_of_parents_to_keep = round(grid_population_size/2) #/2 = Berücksichtige Hälfte der Vorgängerpopulationslösunegn\n",
    "\n",
    "                        packing_algorithm = Packing_Algorithm(grid_order_instance, grid_population_size, self.grid_nr_of_iterations, grid_choosen_parent_pairing, grid_list_of_choosen_crossovers, nr_of_parents_to_keep) # Erzeuge eine Insatnz des Algorithmus mit den jeweiligen Parametern\n",
    "                        best_volume_usage_values, index_best_solution, time_needed, best_solution_improve = packing_algorithm.run_algorithm() # Führe den Algorithmus aus und erhalte eine Liste mit der Volumenauslastung bzw. Index der besten Lösung je Population\n",
    "                        properties_simulation = 'Time needed: ' + str(round(time_needed,2)) + ' - PopSize: ' + str(grid_population_size) + ' - Pairing: ' + str(grid_choosen_parent_pairing) + ' - Crossover: ' + ' '.join(str(element) for element in grid_list_of_choosen_crossovers) + ' - BI: ' + grid_order_instance #Speichere Eigenschaften der Simulation in einer Variable\n",
    "\n",
    "                        # Füge die Eigenschaften der Simulation als erstes Elemnet den Listen mit den Simulationsergebnissen hinzu\n",
    "                        best_volume_usage_values.insert(0, properties_simulation) \n",
    "                        index_best_solution.insert(0, properties_simulation)\n",
    "\n",
    "                        # Füge die Listen mit den Simulationsergebnissen den Listen mit den Ergebnissen aller Simulationen hinzu\n",
    "                        self.list_volume_usage_values.append(best_volume_usage_values)\n",
    "                        self.list_index_best_solution.append(index_best_solution)\n",
    "                        for i in range(len(packplan)):\n",
    "                            self.list_packplan.append((packplan[i][0], packplan[i][1], packplan[i][2], packplan[i][3], packplan[i][4], packplan[i][5], packplan[i][6], packplan[i][7], packplan[i][8], packplan[i][9]))\n",
    "\n",
    "        \n",
    "            # Speichere die Ergebnisse der Simulation in eine CSV Datei\n",
    "            #self.save_to_csv(grid_order_instance) \n",
    "\n",
    "    # Funktion, die alle übergebenen Ergebnisse einer Simulation in eine CSV Datei speichert\n",
    "    def save_to_csv(self, grid_order_instance):\n",
    "       \n",
    "        # Initialisiere die Dateipfade in  welche die Ergebnisse gespeichert werden sollen\n",
    "        file_path_volume = 'Simulationen//' + str(self.timestamp) + ' BI' + grid_order_instance[:2] + ' Simulation Volumenauslastung mit Mutation.csv'\n",
    "        file_path_index = 'Simulationen//' + str(self.timestamp) + ' BI' + grid_order_instance[:2] + ' Simulation bester Index mit Mutation.csv'\n",
    "        file_path_packplan = 'Simulationen//' + str(self.timestamp) + ' BI' + grid_order_instance[:2] + ' Simulation Packplan.csv'\n",
    "\n",
    "        # Erzeuge Dateframes mit den Simulationsergebnissen\n",
    "        results_volume_usage = pd.DataFrame(self.list_volume_usage_values)\n",
    "        self.list_volume_usage_values = []\n",
    "        results_volume_usage = results_volume_usage.T\n",
    "        result_index_best_solutions = pd.DataFrame(self.list_index_best_solution)\n",
    "        self.list_index_best_solution = []\n",
    "        result_index_best_solutions = result_index_best_solutions.T\n",
    "        results_packplan = pd.DataFrame(self.list_packplan)\n",
    "        self.list_packplan = []\n",
    "\n",
    "        # Speichere die Dataframes in CSV Dateien\n",
    "        # results_volume_usage.to_csv(path_or_buf=file_path_volume, header=False, index=False)\n",
    "        # result_index_best_solutions.to_csv(path_or_buf=file_path_index, header=False, index=False)\n",
    "        results_packplan.to_csv(path_or_buf=file_path_packplan, header=False, index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datenvorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenvorverarbeitung\n",
    "def data_preparation (order_file_name, container_file_name):\n",
    "    \n",
    "    '''Importiere  Bestelldaten und Containerdaten'''\n",
    "    \n",
    "    # Lese Containerdaten ein\n",
    "    container_list = pd.read_excel(container_file_name, sheet_name = \"Container\", skiprows = 1)\n",
    "    \n",
    "    # Erzeuge eine Liste für die Containertypen und speichere die relevanten Informationen darin ab\n",
    "    container_data = []\n",
    "    for i in range(len(container_list)):\n",
    "        container_type = (container_list[\"Länge innen [mm]\"][i],container_list[\"Breite innen [mm]\"][i],container_list[\"Höhe innen [mm]\"][i], \n",
    "            round(container_list[\"Fixkosten gesamt\"][i],2), round(container_list[\"Max.Gewicht [kg]\"][i],2))\n",
    "        container_data.append(container_type)\n",
    "\n",
    "    # Lese die Bestelldaten ein\n",
    "    order_list = pd.read_excel(order_file_name)\n",
    "    \n",
    "    # Erzeuge eine Liste für die Packstücke der Bestellung und speichere die relevanten Informationen darin ab\n",
    "    start = 0 # Hilfsvariable für Tabellenindex\n",
    "    end = start + 1 # Hilfsvariable für Tabellenindex\n",
    "    order_data = [] \n",
    "    for i in range(0, len(order_list)):\n",
    "        packaging_unit = (int(order_list[start:end][\"Länge [mm]\"]),int(order_list[start:end][\"Breite [mm]\"]), int(order_list[start:end][\"Höhe [mm]\"]), float(order_list[start:end][\"Gewicht [kg]\"]), \n",
    "                          str(order_list[\"Orientierungen\"][start]))\n",
    "        order_data.append(packaging_unit)\n",
    "        start = start + 1\n",
    "        end = end + 1\n",
    "    '''Bestelldaten und Containerdaten importiert'''\n",
    "    \n",
    "    '''Erzeuge die modifizierte Bestelldaten'''\n",
    "    \n",
    "    modified_order_data = [] # Liste zur Speicherung der modifizierten Bestelldaten\n",
    "    ID = 0 # Fortlaufende Variable zur Zuweisung der Packstück ID\n",
    "    \n",
    "    # Durchlaufe die Packstücke aus den Bestelldaten\n",
    "    for i in range(len(order_data)):\n",
    "        \n",
    "            # Rufe die Packstückdimensionen ab\n",
    "            unit_dimensions = (order_data[i][0],order_data[i][1],order_data[i][2]) \n",
    "            # Sortiere die Packstückdimensionen absteigend\n",
    "            sorted_unit_dimensions = sorted(unit_dimensions, reverse = True)\n",
    "            # Erzeuge sämtliche Orientierungsmöglichkeiten\n",
    "            all_orientations = list(itertools.permutations(sorted_unit_dimensions)) \n",
    "            \n",
    "            # Berücksichtige nun die Orientierungsrestriktionen und entferne verbotene Orientierungen            \n",
    "            # Rufe zunächst die zugelassenen Orientierungen ab\n",
    "            orientations_permitted = list(order_data[i][4]) \n",
    "            # Erzeuge eine Liste, in der die Indizes der verbotenen Orientierungen abgespeichert werden\n",
    "            index_to_drop = [] \n",
    "            for j in range(1, 7): # Suche nach Kennziffern 1 - 6 \n",
    "                if str(j) not in orientations_permitted: # Wenn Kennziffer nicht erlaubt, dann füge den Index der Liste hinzu\n",
    "                    index_to_drop.append((j-1)) #Kennziffer 1 steht an Position 0. Daher j - 1.\n",
    "            # Sortiere jetzt die Indizes die zu entfernen sind\n",
    "            index_to_drop = sorted(index_to_drop, reverse = True)\n",
    "            # Entferne  nun die verbotenen Orientierungen\n",
    "            for itd in index_to_drop:\n",
    "                all_orientations.pop(itd) \n",
    "            \n",
    "            # Erzeuge ein modifiziertes Packstücke MPS\n",
    "            MPS = [] \n",
    "            \n",
    "            ID = i + 1 # Gebe Packstücken eine eindeutige ID. Dies ermöglicht eine Unterscheidung von identischen Packstücken.\n",
    "            for orientation in all_orientations:\n",
    "                area = (orientation[0] * orientation[1]) / 100 # Errechne die Grundfläche einer Orientierung\n",
    "                volume = (orientation[0] * orientation[1] * orientation [2]) / 1000 # Errechne das Packstückvolumen\n",
    "                # Füge dem MPS für jede zugelassene Orientierung folgende Informationen hinzu: \n",
    "                # Grundfläche, Packstück ID, Länge, Breite, Höhe, Gewicht, Volumen\n",
    "                MPS_position = (area, ID, orientation[0], orientation[1], orientation[2], order_data[i][3], round(volume, 2))\n",
    "                MPS.append(MPS_position)\n",
    "\n",
    "            # Füge das MPS den modfizierten Bestelldaten hinzu\n",
    "            modified_order_data.append(MPS)\n",
    "            \n",
    "    # Sortiere jedes MPS absteigend nach der Grundfläche der Orientierungsvarianten\n",
    "    for i, MPS in enumerate(modified_order_data):\n",
    "        modified_order_data[i] = sorted(MPS, key=lambda elem: elem[0], reverse = True) \n",
    "    \n",
    " \n",
    "    # Sortiere die MPS nach Volumen\n",
    "    sorted_modified_order_data = [] # Liste in der die sortierten MPS gespeichert werden\n",
    "    volume_index_old = [] # Volumen und aktuellen Index aller MPS der unsortierten modifizierten Bestelldaten abspeichern\n",
    "    index = 0\n",
    "    for MPS in modified_order_data:\n",
    "        volume_index = (MPS[0][6], index)\n",
    "        volume_index_old.append(volume_index)\n",
    "        index += 1\n",
    "    \n",
    "    # Sortiere die erzeugte Liste\n",
    "    volume_index_new = sorted (volume_index_old, reverse = True) \n",
    "    \n",
    "    # Nun ist eine Zuordnung zwischen den Indizes der unsortierten Bestelldaten und den nach Volumen sortierten modifzierten Bestelldaten möglich\n",
    "    for index_to_change in volume_index_new:\n",
    "        sorted_modified_order_data.append(modified_order_data[index_to_change[1]]) # Index steht an Position 1\n",
    "        \n",
    "    '''Modifizierte Bestelldaten erzeugt'''\n",
    "\n",
    "    # Gebe Liste mit Instanze aus modifizierte Bestelldaten mit zufälliger Reihenfolge und Containerdaten zurück\n",
    "    return sorted_modified_order_data, container_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Restriktionen in Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Platzierungsbedingung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def Check_Placement_Modified_Stacking ((int, int, int) container, float max_weight, float carried_weight, article_locations, (float, int, int, int, int, float, float) orientation, int stack_raw_width, int stack_length, unsigned int stack_box_length, int stack_box_height, int stack_box_width):\n",
    "\n",
    "    center_of_gravity_width = orientation[2]/2 # Schwerpunktbreite \n",
    "    center_of_gravity_length = orientation[3]/2 # Schwerpunktlänge\n",
    "    cdef int add_allowed = 0\n",
    "\n",
    "    # Prüfe ob das Packstück auf den Stapel passt\n",
    "    if ((center_of_gravity_width <= stack_raw_width) and # Schwerpunkt darf nicht die Stapelbreite überschreiten\n",
    "        (center_of_gravity_length <= stack_length) and # Schwerpunkt darf nicht die Stapellänge überschreiten\n",
    "        (orientation[4] + stack_box_height <= container[1]) and # Containerhöhe darf nicht überschritten werden\n",
    "        (orientation[3] + stack_box_length <= container[2]) and # Containerlänge darf nicht überschritten werden\n",
    "        (orientation[2] + stack_box_width <= container[0]) and # Containerbreite darf nicht überschritten werden\n",
    "        (carried_weight + orientation[5] <= max_weight)): # Gewichtsobergrenzte darf nicht überschritten werden\n",
    "\n",
    "        add_allowed = True\n",
    "\n",
    "        # Prüfe, ob Überschneidungen zu anderen Packstücke existieren\n",
    "        for article in article_locations:\n",
    "            if ((((article.y <= stack_box_height) and (article.height + article.y > stack_box_height)) or ((article.y > stack_box_height) and (article.y < stack_box_height + orientation[4])))and # Überschneidungen in der Höhe\n",
    "                (((article.x > stack_box_width) and (article.x < stack_box_width + orientation[2])) or ((article.x <= stack_box_width) and (article.x + article.width > stack_box_width))) and # Überschneidungen in der Breite\n",
    "                (((article.z > stack_box_length) and (article.z < stack_box_length + orientation[3])) or ((article.z <= stack_box_length) and (article.z +article.length > stack_box_length)))): # Überschneidungen in der Länge\n",
    "                    \n",
    "                add_allowed = False\n",
    "                break\n",
    "\n",
    "    return add_allowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def Check_Placement (article_to_add, articles_in_raw, (int, int, int) container, float max_weight, float carried_weight, (float, int, int, int, int, float, float) orientation, unsigned int raw_width, int raw_length, unsigned int box_length, unsigned int box_height, float factor_overfilling):\n",
    "\n",
    "    # cdef int add_allowed = 0\n",
    "    # add_allowed: cython.int = 0\n",
    "    cdef int add_allowed = 0\n",
    "\n",
    "\n",
    "    if ((orientation[2] <= raw_width) and # Breite der Orientierung muss kleiner gleich der Breite des Leerraums sein\n",
    "        (orientation[3] <= raw_length * factor_overfilling) and # Länge der Orientierung darf Reihenlänge bis zu einer gewissen Toleranz T nicht überschreiten. T = factor_overfilling.\n",
    "        (orientation[4] + box_height <= container[1]) and # Höhe der Orientierung zzgl. der Höhenposition muss kleiner gleich der Containerhöhe sein\n",
    "        (orientation[3] + box_length <= container[2]) and # Länge der Orientierung zzgl. der Längenpoistion darf Containerlänge nicht überschreiten\n",
    "        ((carried_weight + orientation[5]) <= max_weight)): # Sicherstellung der Gewichtseinhaltung\n",
    "\n",
    "            # Stelle sicher, dass zu betrachtetes Packstück noch nicht gepackt wurde\n",
    "            # Bedingung wird aufgrund der erzeugten Nebenreihen benötigt\n",
    "            add_allowed = article_to_add not in articles_in_raw\n",
    "\n",
    "    return add_allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bedingung für Traglast einzelner Packstücke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def Calculate_Overlapping_Areas(selected_orientation, articles_from_extension):\n",
    "    # Liefert für jedes Packstück der Stapelgrundfläche, auf das gestapelt wird, zu welchem Anteil es von dem zu packenden Packstück überdeckt wird\n",
    "    \n",
    "    # Definiere Datentypen\n",
    "    cdef int width_article_to_pack\n",
    "    cdef int length_article_to_pack\n",
    "    cdef float width_coordinate_article_to_pack\n",
    "    cdef float length_coordinate_article_to_pack\n",
    "    \n",
    "    cdef int package_ID_article_base\n",
    "    cdef int width_article_base\n",
    "    cdef int length_article_base\n",
    "    cdef float width_coordinate_article_base\n",
    "    cdef float length_coordinate_article_base\n",
    "\n",
    "    cdef float overlapping_area\n",
    "    cdef float overlap_in_weight\n",
    "    cdef float overlap_in_length\n",
    "\n",
    "    # Initialisiere Listen zum Speichern der Packstück ID aller Packstücke, welche durch das zu packende Packstück überdeckt werden + die Göße der übderdeckten Fläche\n",
    "    overlapping_area_of_each_base_article  = []\n",
    "\n",
    "    \n",
    "    # Initialisiere Variablen für die Maße und Koordinaten des zu packenden Packstücks\n",
    "    width_article_to_pack = selected_orientation[2] #0\n",
    "    length_article_to_pack = selected_orientation[0] #2\n",
    "    width_coordinate_article_to_pack = selected_orientation[3] #3\n",
    "    length_coordinate_article_to_pack = selected_orientation[5]\n",
    "\n",
    "    for article in articles_from_extension: # Durchlaufe alle Packstück der Stapelgrundfläche\n",
    "        \n",
    "        # Initialisiere Variablen für die Maße, Koordinaten und ID des zu Packstücks aus der Fläche, die als Basis für den Stapel dient\n",
    "        package_ID_article_base = article[0] # Packstück ID\n",
    "        width_article_base = article[1] # Packstück Breite\n",
    "        length_article_base = article[2] # Packstück Länge\n",
    "        width_coordinate_article_base = article[3] # Packstück Breitenkoordinate\n",
    "        length_coordinate_article_base = article[4] # Packstück Längenkoordinate\n",
    "\n",
    "        # Initialisiere Variable für die Überlappende Fläche\n",
    "        overlapping_area = 0\n",
    "        \n",
    "    \n",
    "        # Brechne die Überlappung in der Breite\n",
    "        overlap_in_weight = min((width_coordinate_article_base + width_article_base), (width_coordinate_article_to_pack + width_article_to_pack)) - max(width_coordinate_article_base, width_coordinate_article_to_pack)\n",
    "        # Berechne die Überlappung in der Länge\n",
    "        overlap_in_length = min((length_coordinate_article_base + length_article_base), (length_coordinate_article_to_pack + length_article_to_pack)) - max(length_coordinate_article_base, length_coordinate_article_to_pack)\n",
    "        \n",
    "        if (overlap_in_weight >= 0) and (overlap_in_length >= 0):\n",
    "            overlapping_area = overlap_in_weight * overlap_in_length # Berechnen die überlappende Fläche\n",
    "        \n",
    "        if (overlapping_area > 0): # Überprüfe, ob es eine überlappende Fläche gibt\n",
    "            # Füge Informationen über das Packstück der Stapelgrundfläche der Liste hinzu\n",
    "            overlapping_area_of_each_base_article.append((package_ID_article_base, overlapping_area))\n",
    "   \n",
    "\n",
    "\n",
    "    return overlapping_area_of_each_base_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anwednung und Ergebnisausgabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ausführen des Algorithmus mit Line-by-Line-Profiler \n",
    "# %load_ext line_profiler\n",
    "\n",
    "# # Erzeuge eine Instanz des Algorithmus mit den gewünschten Paramtern (Dateiname der Bestelldaten, Populationsgröße, Variante der Paarungsselektion, Variante des Crossover, Anzahl zu übernehmende beste Individuen in Folgepopulation)\n",
    "# packing_algorithm = Packing_Algorithm(\"06_Datensatz_50-75 Artikel_leicht_heterogen2\", 10, 10, 0, [0], 1)\n",
    "# # Ruf Algorithmus mit Profiler auf und definiere für welche Funktion die Zeit gemessen werden soll\n",
    "# %lprun -f Container.run_Wall_Building packing_algorithm.run_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '01_Datensatz_Beispiel_4.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Starte Simulation mit verschiedenen Parametern\u001b[39;00m\n\u001b[0;32m      2\u001b[0m simulation \u001b[38;5;241m=\u001b[39m Grid_Search() \u001b[38;5;66;03m# Erzeuge eine Instanz der Gittersuche\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_grid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Führe Simulationen mit den in der Gittersuche definierten Parametern durch\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[114], line 42\u001b[0m, in \u001b[0;36mGrid_Search.run_grid_search\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m nr_of_parents_to_keep \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# Berücksichtige die beste Lösung der Vorgängerpopulation\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# nr_of_parents_to_keep = round(grid_population_size/2) #/2 = Berücksichtige Hälfte der Vorgängerpopulationslösunegn\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m packing_algorithm \u001b[38;5;241m=\u001b[39m \u001b[43mPacking_Algorithm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid_order_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_population_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_nr_of_iterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_choosen_parent_pairing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_list_of_choosen_crossovers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnr_of_parents_to_keep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Erzeuge eine Insatnz des Algorithmus mit den jeweiligen Parametern\u001b[39;00m\n\u001b[0;32m     43\u001b[0m best_volume_usage_values, index_best_solution, time_needed, best_solution_improve \u001b[38;5;241m=\u001b[39m packing_algorithm\u001b[38;5;241m.\u001b[39mrun_algorithm() \u001b[38;5;66;03m# Führe den Algorithmus aus und erhalte eine Liste mit der Volumenauslastung bzw. Index der besten Lösung je Population\u001b[39;00m\n\u001b[0;32m     44\u001b[0m properties_simulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime needed: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mround\u001b[39m(time_needed,\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - PopSize: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(grid_population_size) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - Pairing: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(grid_choosen_parent_pairing) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - Crossover: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(element) \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m grid_list_of_choosen_crossovers) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - BI: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m grid_order_instance \u001b[38;5;66;03m#Speichere Eigenschaften der Simulation in einer Variable\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[113], line 20\u001b[0m, in \u001b[0;36mPacking_Algorithm.__init__\u001b[1;34m(self, order_instance, population_size, nr_of_iterations, choosen_parent_pairing, list_of_choosen_crossovers, nr_of_parents_to_keep)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnr_of_parents_to_keep \u001b[38;5;241m=\u001b[39m nr_of_parents_to_keep \u001b[38;5;66;03m# Anzahl der besten Individuen, die in die Folgegeneration übernommen werden sollen. Hat nur Auswirkungen, wenn die lokale Suche in der Funktion run_all_offspring_generations der Klasse Populations nicht durchgeführt wird.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Rufe Datenvorverarbeitung auf und erhalte die initialen modifizierten Bestelldaten sortiert nach Packstückvolumen und Grundfläche der Orientierungen sowie die Containerdaten\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_modified_order_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_preparation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Initialisiere die durch die Basisheuristik mit der initialen Packreihenfolge berechnete Lösung\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_solution_base \u001b[38;5;241m=\u001b[39m Solution(copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_modified_order_data), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer_data) \u001b[38;5;66;03m# erzeugte einer leere Lösung und Initailisiere sie mit der initialen MPS Packreihenfolge & den Containerdaten\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[115], line 17\u001b[0m, in \u001b[0;36mdata_preparation\u001b[1;34m(order_file_name, container_file_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m     container_data\u001b[38;5;241m.\u001b[39mappend(container_type)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Lese die Bestelldaten ein\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m order_list \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Erzeuge eine Liste für die Packstücke der Bestellung und speichere die relevanten Informationen darin ab\u001b[39;00m\n\u001b[0;32m     20\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m# Hilfsvariable für Tabellenindex\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1563\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1563\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1566\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1567\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1568\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1569\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1570\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1417\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1419\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1421\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1422\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1423\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:872\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    873\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '01_Datensatz_Beispiel_4.xlsx'"
     ]
    }
   ],
   "source": [
    "# Starte Simulation mit verschiedenen Parametern\n",
    "simulation = Grid_Search() # Erzeuge eine Instanz der Gittersuche\n",
    "simulation.run_grid_search() # Führe Simulationen mit den in der Gittersuche definierten Parametern durch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "27b1f2cb6d215e29e3a7508497cfa6d5e8351676668caeb8c109f68d86cce293"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
